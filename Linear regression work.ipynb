{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, df is created from original dataset\n",
    "# should be replaced by cleaned version once quality plan is complete\n",
    "df = pd.read_csv('OnlineNewsPopularity.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle rows of data set and split into training and testing sets\n",
    "# because we have large dataset, cross-validation should not be needed\n",
    "# will use a 75:25 split\n",
    "df = shuffle(df)\n",
    "df_train = df[:750]\n",
    "df_test = df[750:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'timedelta', 'n_tokens_title', 'n_tokens_content',\n",
       "       'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens',\n",
       "       'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
       "       'average_token_length', 'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, just a random selection of features. just to lay out the skeleton for a fit\n",
    "lm = sm.ols(formula=\"shares ~ n_tokens_title + num_keywords + kw_avg_avg + title_sentiment_polarity\", data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                  -1422.532301\n",
       "n_tokens_title               -21.150326\n",
       "num_keywords                 214.079386\n",
       "kw_avg_avg                     1.189886\n",
       "title_sentiment_polarity    1585.407156\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep in mind the value range for shares when interpreting coefficients, i suppose.\n",
    "# quite different to the 0 or 1 we were dealing with before.\n",
    "df['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th> <td>   0.024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.019</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.643</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>0.00104</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:58:04</td>     <th>  Log-Likelihood:    </th> <td> -7971.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   750</td>      <th>  AIC:               </th> <td>1.595e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   745</td>      <th>  BIC:               </th> <td>1.598e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>-1422.5323</td> <td> 2460.650</td> <td>   -0.578</td> <td> 0.563</td> <td>-6253.166</td> <td> 3408.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>           <td>  -21.1503</td> <td>  173.498</td> <td>   -0.122</td> <td> 0.903</td> <td> -361.754</td> <td>  319.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>             <td>  214.0794</td> <td>  192.597</td> <td>    1.112</td> <td> 0.267</td> <td> -164.018</td> <td>  592.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>               <td>    1.1899</td> <td>    0.306</td> <td>    3.886</td> <td> 0.000</td> <td>    0.589</td> <td>    1.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th> <td> 1585.4072</td> <td> 1357.351</td> <td>    1.168</td> <td> 0.243</td> <td>-1079.282</td> <td> 4250.096</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1160.615</td> <th>  Durbin-Watson:     </th>  <td>   2.026</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>370126.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 9.058</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>110.312</td> <th>  Cond. No.          </th>  <td>2.30e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.024\n",
       "Model:                            OLS   Adj. R-squared:                  0.019\n",
       "Method:                 Least Squares   F-statistic:                     4.643\n",
       "Date:                Sun, 22 Apr 2018   Prob (F-statistic):            0.00104\n",
       "Time:                        10:58:04   Log-Likelihood:                -7971.9\n",
       "No. Observations:                 750   AIC:                         1.595e+04\n",
       "Df Residuals:                     745   BIC:                         1.598e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                -1422.5323   2460.650     -0.578      0.563   -6253.166    3408.101\n",
       "n_tokens_title             -21.1503    173.498     -0.122      0.903    -361.754     319.454\n",
       "num_keywords               214.0794    192.597      1.112      0.267    -164.018     592.177\n",
       "kw_avg_avg                   1.1899      0.306      3.886      0.000       0.589       1.791\n",
       "title_sentiment_polarity  1585.4072   1357.351      1.168      0.243   -1079.282    4250.096\n",
       "==============================================================================\n",
       "Omnibus:                     1160.615   Durbin-Watson:                   2.026\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           370126.259\n",
       "Skew:                           9.058   Prob(JB):                         0.00\n",
       "Kurtosis:                     110.312   Cond. No.                     2.30e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.3e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()\n",
    "# from these random features, n_tokens_title has a notably high p-value. \n",
    "# the r-squared value is low, as might be expected from random features.\n",
    "# we need to develop a good understanding of these metrics, especially p-values,\n",
    "# r-squared and coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7466     4600.134541\n",
       "34904    3689.425692\n",
       "2374     2586.939639\n",
       "4984     5416.731725\n",
       "6625     4233.134402\n",
       "27684    4191.055560\n",
       "25535    2475.832400\n",
       "2275     3287.025294\n",
       "7481     4213.155944\n",
       "4293     5689.855926\n",
       "30741    3967.930427\n",
       "12002    3921.965412\n",
       "24740    3321.479245\n",
       "24877    3091.522475\n",
       "12677    2493.215465\n",
       "33505    2372.767244\n",
       "31317    3453.349246\n",
       "31295    2587.860645\n",
       "18901    5674.256428\n",
       "37994    3084.118586\n",
       "5244     3025.138295\n",
       "4520     3334.498217\n",
       "8483     6411.737306\n",
       "2230     3353.717545\n",
       "9667     4118.818230\n",
       "35496    4100.439230\n",
       "30547    3752.927774\n",
       "5731     4301.618814\n",
       "19390    2671.187352\n",
       "7640     5672.493546\n",
       "8726     3180.086296\n",
       "25600    6288.264303\n",
       "14382    3133.507895\n",
       "28525    3774.255372\n",
       "17160    2514.883155\n",
       "17025    2372.348868\n",
       "3907     2822.497077\n",
       "3438     3102.075674\n",
       "27731    4027.761339\n",
       "33386    2084.973363\n",
       "27052    6393.645513\n",
       "16107    2385.720072\n",
       "17184    4590.791004\n",
       "17716    8655.767735\n",
       "17898    3459.369713\n",
       "3430     2978.685910\n",
       "39338    4250.583294\n",
       "2316     5430.216086\n",
       "24466    4222.328213\n",
       "23773    3841.593305\n",
       "17607    2236.975065\n",
       "34482    4329.156635\n",
       "26528    4167.797321\n",
       "9217     3685.073005\n",
       "3920     3744.618976\n",
       "25776    3359.887118\n",
       "12682    6593.848133\n",
       "27688    3597.872381\n",
       "6628     2392.860079\n",
       "18525    4376.803544\n",
       "25547    5942.816777\n",
       "38411    3895.201427\n",
       "21484    5179.222259\n",
       "26477    3703.361805\n",
       "15842    6149.230220\n",
       "23719    4006.346786\n",
       "37329    3657.333399\n",
       "36016    1851.326428\n",
       "38477    1611.697780\n",
       "2124     2665.452541\n",
       "23191    2797.530822\n",
       "39527    6642.536865\n",
       "19602    5540.437123\n",
       "25947    9731.330069\n",
       "20303    2722.987999\n",
       "13825    7139.742201\n",
       "14472    3564.688767\n",
       "15217    2598.159418\n",
       "21324    5710.790054\n",
       "32354    3891.798580\n",
       "27441    6398.606623\n",
       "12069    2153.502572\n",
       "34553    3057.273945\n",
       "6977     5100.916635\n",
       "24326    3687.177196\n",
       "7792     2600.421615\n",
       "14044    2904.828099\n",
       "39515    3257.274011\n",
       "22919    2743.289272\n",
       "21205    3273.438514\n",
       "3714     4752.345283\n",
       "21494    5384.223351\n",
       "35286    3178.226506\n",
       "37168    4166.523067\n",
       "20        443.307313\n",
       "22975    3542.267736\n",
       "10831    4015.718571\n",
       "7683     3029.366251\n",
       "30593    2518.471326\n",
       "14137    2023.356917\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy of the model\n",
    "# to assess accuracy for a regression model (in addition to the r-squared value auto-generated above),\n",
    "# we can find the mean squared error (or root mean squared error)\n",
    "# we could also convert to a classification problem (by setting threshold of popularity and dividing \n",
    "# target into 1 for popular and 0 for unpopular) and then getting the accuracy score from predictions\n",
    "# on a sample from the training set.\n",
    "train_predictions_sample = lm.predict(df_train[:100])\n",
    "train_predictions_sample\n",
    "# calculate predictions for 'shares' on a small sample of the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-98d30ccb7315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shares'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predictions_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(df_train['shares'][:100], train_predictions_sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
