{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, df is created from original dataset\n",
    "# should be replaced by cleaned version once quality plan is complete\n",
    "df = pd.read_csv('OnlineNewsPopularity.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "df = df.drop(['url', 'timedelta'], axis=1)\n",
    "# drop non-predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29733.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 75:25 split\n",
    "df.shape[0] * .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle rows of data set and split into training and testing sets\n",
    "# because we have large dataset, cross-validation should not be needed\n",
    "# will use a 75:25 split\n",
    "df = shuffle(df)\n",
    "df_train = df[:29733]\n",
    "df_test = df[29733:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, just a random selection of features. just to lay out the skeleton for a fit\n",
    "lm = sm.ols(formula=\"shares ~ n_tokens_title + num_keywords + kw_avg_avg + title_sentiment_polarity\", data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                  -732.114947\n",
       "n_tokens_title               38.181469\n",
       "num_keywords                 86.309166\n",
       "kw_avg_avg                    0.989290\n",
       "title_sentiment_polarity    286.973203\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep in mind the value range for shares when interpreting coefficients, i suppose.\n",
    "# quite different to the 0 or 1 we were dealing with before.\n",
    "df['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th>  <td>   0.013</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.012</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   94.45</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>5.65e-80</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:42:53</td>     <th>  Log-Likelihood:    </th> <td>-3.2148e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 29733</td>      <th>  AIC:               </th>  <td>6.430e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 29728</td>      <th>  BIC:               </th>  <td>6.430e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td> -732.1149</td> <td>  465.541</td> <td>   -1.573</td> <td> 0.116</td> <td>-1644.595</td> <td>  180.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>           <td>   38.1815</td> <td>   32.932</td> <td>    1.159</td> <td> 0.246</td> <td>  -26.367</td> <td>  102.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>             <td>   86.3092</td> <td>   36.594</td> <td>    2.359</td> <td> 0.018</td> <td>   14.584</td> <td>  158.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>               <td>    0.9893</td> <td>    0.052</td> <td>   19.114</td> <td> 0.000</td> <td>    0.888</td> <td>    1.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th> <td>  286.9732</td> <td>  262.731</td> <td>    1.092</td> <td> 0.275</td> <td> -227.991</td> <td>  801.937</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>82134.936</td> <th>  Durbin-Watson:     </th>    <td>   2.004</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>4438681697.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>35.128</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>1894.533</td>  <th>  Cond. No.          </th>    <td>2.29e+04</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.013\n",
       "Model:                            OLS   Adj. R-squared:                  0.012\n",
       "Method:                 Least Squares   F-statistic:                     94.45\n",
       "Date:                Sun, 22 Apr 2018   Prob (F-statistic):           5.65e-80\n",
       "Time:                        13:42:53   Log-Likelihood:            -3.2148e+05\n",
       "No. Observations:               29733   AIC:                         6.430e+05\n",
       "Df Residuals:                   29728   BIC:                         6.430e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                 -732.1149    465.541     -1.573      0.116   -1644.595     180.365\n",
       "n_tokens_title              38.1815     32.932      1.159      0.246     -26.367     102.730\n",
       "num_keywords                86.3092     36.594      2.359      0.018      14.584     158.034\n",
       "kw_avg_avg                   0.9893      0.052     19.114      0.000       0.888       1.091\n",
       "title_sentiment_polarity   286.9732    262.731      1.092      0.275    -227.991     801.937\n",
       "==============================================================================\n",
       "Omnibus:                    82134.936   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       4438681697.575\n",
       "Skew:                          35.128   Prob(JB):                         0.00\n",
       "Kurtosis:                    1894.533   Cond. No.                     2.29e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.29e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()\n",
    "# from these random features, there are no notably high p-values. \n",
    "# the r-squared value is low, as might be expected from random features.\n",
    "# we need to develop a good understanding of these metrics, especially p-values,\n",
    "# r-squared and coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test accuracy of the model\n",
    "# to assess accuracy for a regression model (in addition to the r-squared value auto-generated above),\n",
    "# we can find the mean squared error (or root mean squared error)\n",
    "# we could also convert to a classification problem (by setting threshold of popularity and dividing \n",
    "# target into 1 for popular and 0 for unpopular) and then getting the accuracy score from predictions\n",
    "# on a sample from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29733, 59)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     29733.000000\n",
       "mean       3412.690008\n",
       "std       12082.429534\n",
       "min           1.000000\n",
       "25%         949.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reference\n",
    "df_train['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean      3366.799345\n",
       "std       1292.265821\n",
       "min        -23.814679\n",
       "25%       2610.434354\n",
       "50%       3117.366939\n",
       "75%       3777.690125\n",
       "max      18109.299364\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions_sample = df_train[:1000]\n",
    "predictions = lm.predict(train_predictions_sample)\n",
    "predictions.describe()\n",
    "# these predictions are obviously very poor with the current random features model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757701279.57806432"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean squared error\n",
    "mean_squared_error(df_train['shares'][:1000], predictions)\n",
    "# something has gone wrong here, obviously. mse is gigantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn into classification problem and test accuracy score\n",
    "# Use a 3813 shares threshold for classification as popular (top 25 %). \n",
    "# or could only could extremely high share values as being 'viral' (val 1) and the rest being \n",
    "# 'not viral' (val 0)\n",
    "predictions = predictions.apply(lambda res: 1 if res > 3813 else 0)\n",
    "# calculate predictions for 'shares' on a sample of the set\n",
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martincasey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    24399\n",
       "1     5334\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train['shares_binary'] = df_train['shares'].apply((lambda res: 1 if res > 3784 else 0), axis = 1)\n",
    "# above doesn't work because the single col 'shares' is a series, not a dataframe. axis arg makes no sense\n",
    "# maybe use df_train[['shares']] instead, which should be a dataframe with just one col\n",
    "\n",
    "#df_train['shares_binary'] = df_train[['shares']].apply(lambda res: 1 if res > 3784 else 0)\n",
    "df_train['shares_binary'] = np.where(df_train['shares'] >=3784, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81999999999999995"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_train['shares_binary'][:1000], predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[820,   0],\n",
       "       [180,   0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_train['shares_binary'][:1000], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       820\n",
      "          1       0.00      0.00      0.00       180\n",
      "\n",
      "avg / total       0.67      0.82      0.74      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martincasey/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_train['shares_binary'][:1000], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discuss above metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
