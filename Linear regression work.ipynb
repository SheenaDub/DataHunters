{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, df is created from original dataset\n",
    "# should be replaced by cleaned version once quality plan is complete\n",
    "df = pd.read_csv('OnlineNewsPopularity.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "df = df.drop(['url', 'timedelta'], axis=1)\n",
    "# drop non-predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29733.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 75:25 split\n",
    "df.shape[0] * .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle rows of data set and split into training and testing sets\n",
    "# because we have large dataset, cross-validation should not be needed\n",
    "# will use a 75:25 split\n",
    "df = shuffle(df)\n",
    "df_train = df[:29733]\n",
    "df_test = df[29733:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, just a random selection of features. just to lay out the skeleton for a fit\n",
    "lm = sm.ols(formula=\"shares ~ n_tokens_title + num_keywords + kw_avg_avg + title_sentiment_polarity\", data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                  -951.332141\n",
       "n_tokens_title               55.540904\n",
       "num_keywords                109.103743\n",
       "kw_avg_avg                    0.921724\n",
       "title_sentiment_polarity    311.143841\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep in mind the value range for shares when interpreting coefficients, i suppose.\n",
    "# quite different to the 0 or 1 we were dealing with before. \n",
    "df['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th>  <td>   0.015</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.015</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   114.7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>2.96e-97</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:51:39</td>     <th>  Log-Likelihood:    </th> <td>-3.1663e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 29733</td>      <th>  AIC:               </th>  <td>6.333e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 29728</td>      <th>  BIC:               </th>  <td>6.333e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td> -951.3321</td> <td>  395.488</td> <td>   -2.405</td> <td> 0.016</td> <td>-1726.505</td> <td> -176.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>           <td>   55.5409</td> <td>   27.987</td> <td>    1.985</td> <td> 0.047</td> <td>    0.685</td> <td>  110.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>             <td>  109.1037</td> <td>   31.042</td> <td>    3.515</td> <td> 0.000</td> <td>   48.260</td> <td>  169.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>               <td>    0.9217</td> <td>    0.044</td> <td>   20.820</td> <td> 0.000</td> <td>    0.835</td> <td>    1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th> <td>  311.1438</td> <td>  222.243</td> <td>    1.400</td> <td> 0.162</td> <td> -124.461</td> <td>  746.749</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>81983.961</td> <th>  Durbin-Watson:     </th>    <td>   2.009</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>6297599780.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>34.731</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>2256.552</td>  <th>  Cond. No.          </th>    <td>2.29e+04</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.015\n",
       "Model:                            OLS   Adj. R-squared:                  0.015\n",
       "Method:                 Least Squares   F-statistic:                     114.7\n",
       "Date:                Sun, 22 Apr 2018   Prob (F-statistic):           2.96e-97\n",
       "Time:                        14:51:39   Log-Likelihood:            -3.1663e+05\n",
       "No. Observations:               29733   AIC:                         6.333e+05\n",
       "Df Residuals:                   29728   BIC:                         6.333e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                 -951.3321    395.488     -2.405      0.016   -1726.505    -176.159\n",
       "n_tokens_title              55.5409     27.987      1.985      0.047       0.685     110.397\n",
       "num_keywords               109.1037     31.042      3.515      0.000      48.260     169.948\n",
       "kw_avg_avg                   0.9217      0.044     20.820      0.000       0.835       1.008\n",
       "title_sentiment_polarity   311.1438    222.243      1.400      0.162    -124.461     746.749\n",
       "==============================================================================\n",
       "Omnibus:                    81983.961   Durbin-Watson:                   2.009\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       6297599780.016\n",
       "Skew:                          34.731   Prob(JB):                         0.00\n",
       "Kurtosis:                    2256.552   Cond. No.                     2.29e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.29e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()\n",
    "# from these random features, there are no notably high p-values. \n",
    "# the r-squared value is low, as might be expected from random features.\n",
    "# we need to develop a good understanding of these metrics, especially p-values,\n",
    "# r-squared and coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test accuracy of the model\n",
    "# to assess accuracy for a regression model (in addition to the r-squared value auto-generated above),\n",
    "# we can find the mean squared error (or root mean squared error)\n",
    "# we could also convert to a classification problem (by setting threshold of popularity and dividing \n",
    "# target into 1 for popular and 0 for unpopular) and then getting the accuracy score from predictions\n",
    "# on a sample from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29733, 59)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     29733.000000\n",
       "mean       3330.728887\n",
       "std       10278.859645\n",
       "min           4.000000\n",
       "25%         943.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reference\n",
    "df_train['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean      3362.932680\n",
       "std       1298.718982\n",
       "min        427.850407\n",
       "25%       2637.468755\n",
       "50%       3098.993884\n",
       "75%       3794.033132\n",
       "max      19439.053711\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions_sample = df_train[:1000]\n",
    "predictions = lm.predict(train_predictions_sample)\n",
    "predictions.describe()\n",
    "# these predictions are obviously very poor with the current random features model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37383938.013037324"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean squared error\n",
    "mse = mean_squared_error(df_train['shares'][:1000], predictions)\n",
    "mse\n",
    "# something has gone wrong here, obviously. mse is gigantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6114.240591687354"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error for comparison\n",
    "sqrt(mse)\n",
    "# need to understand more about these numbers and discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    754\n",
       "1    246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn into classification problem and test accuracy score\n",
    "# Use a 2800 shares threshold for classification as popular (top 25 %). \n",
    "# or could only could extremely high share values as being 'viral' (val 1) and the rest being \n",
    "# 'not viral' (val 0)\n",
    "predictions = predictions.apply(lambda res: 1 if res > 3813 else 0)\n",
    "# calculate predictions for 'shares' on a sample of the set\n",
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martincasey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    24427\n",
       "1     5306\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train['shares_binary'] = df_train['shares'].apply((lambda res: 1 if res > 2800 else 0), axis = 1)\n",
    "# above doesn't work because the single col 'shares' is a series, not a dataframe. axis arg makes no sense\n",
    "# maybe use df_train[['shares']] instead, which should be a dataframe with just one col\n",
    "\n",
    "#df_train['shares_binary'] = df_train[['shares']].apply(lambda res: 1 if res > 2800 else 0)\n",
    "df_train['shares_binary'] = np.where(df_train['shares'] >=3784, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73399999999999999"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_train['shares_binary'][:1000], predictions) \n",
    "# this figure looks not too bad, but it's only predicting membership of the top 25% (if i've dont it right)\n",
    "# look at other thresholds etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[652, 164],\n",
       "       [102,  82]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(df_train['shares_binary'][:1000], predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  652 \n",
      "False positives:  164 \n",
      "False negatives:  102 \n",
      "True positives:  82\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ',  fn, '\\nTrue positives: ', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.80      0.83       816\n",
      "          1       0.33      0.45      0.38       184\n",
      "\n",
      "avg / total       0.77      0.73      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_train['shares_binary'][:1000], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discuss above metrics. repeat with hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = lm.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.apply(lambda res: 0 if res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
