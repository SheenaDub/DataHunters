{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, df is created from original dataset\n",
    "# should be replaced by cleaned version once quality plan is complete\n",
    "df = pd.read_csv('OnlineNewsPopularity.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "df = df.drop(['url', 'timedelta'], axis=1)\n",
    "# drop non-predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29733.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 75:25 split\n",
    "df.shape[0] * .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle rows of data set and split into training and testing sets\n",
    "# because we have large dataset, cross-validation should not be needed\n",
    "# will use a 75:25 split\n",
    "df = shuffle(df)\n",
    "df_train = df[:29733]\n",
    "df_test = df[29733:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, just a random selection of features. just to lay out the skeleton for a fit\n",
    "lm = sm.ols(formula=\"shares ~ n_tokens_title + num_keywords + kw_avg_avg + title_sentiment_polarity\", data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                  -929.786797\n",
       "n_tokens_title               41.121569\n",
       "num_keywords                120.820045\n",
       "kw_avg_avg                    0.965756\n",
       "title_sentiment_polarity    359.476498\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep in mind the value range for shares when interpreting coefficients, i suppose.\n",
    "# quite different to the 0 or 1 we were dealing with before. \n",
    "df['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th>  <td>   0.012</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.012</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   88.38</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>8.52e-75</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:59:17</td>     <th>  Log-Likelihood:    </th> <td>-3.2100e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 29733</td>      <th>  AIC:               </th>  <td>6.420e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 29728</td>      <th>  BIC:               </th>  <td>6.420e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td> -929.7868</td> <td>  461.388</td> <td>   -2.015</td> <td> 0.044</td> <td>-1834.128</td> <td>  -25.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>           <td>   41.1216</td> <td>   32.445</td> <td>    1.267</td> <td> 0.205</td> <td>  -22.472</td> <td>  104.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>             <td>  120.8200</td> <td>   35.905</td> <td>    3.365</td> <td> 0.001</td> <td>   50.444</td> <td>  191.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>               <td>    0.9658</td> <td>    0.053</td> <td>   18.273</td> <td> 0.000</td> <td>    0.862</td> <td>    1.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th> <td>  359.4765</td> <td>  258.395</td> <td>    1.391</td> <td> 0.164</td> <td> -146.990</td> <td>  865.943</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>81598.269</td> <th>  Durbin-Watson:     </th>    <td>   1.986</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>4325522322.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>34.508</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>1870.278</td>  <th>  Cond. No.          </th>    <td>2.29e+04</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.012\n",
       "Model:                            OLS   Adj. R-squared:                  0.012\n",
       "Method:                 Least Squares   F-statistic:                     88.38\n",
       "Date:                Sun, 22 Apr 2018   Prob (F-statistic):           8.52e-75\n",
       "Time:                        14:59:17   Log-Likelihood:            -3.2100e+05\n",
       "No. Observations:               29733   AIC:                         6.420e+05\n",
       "Df Residuals:                   29728   BIC:                         6.420e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                 -929.7868    461.388     -2.015      0.044   -1834.128     -25.445\n",
       "n_tokens_title              41.1216     32.445      1.267      0.205     -22.472     104.715\n",
       "num_keywords               120.8200     35.905      3.365      0.001      50.444     191.196\n",
       "kw_avg_avg                   0.9658      0.053     18.273      0.000       0.862       1.069\n",
       "title_sentiment_polarity   359.4765    258.395      1.391      0.164    -146.990     865.943\n",
       "==============================================================================\n",
       "Omnibus:                    81598.269   Durbin-Watson:                   1.986\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       4325522322.611\n",
       "Skew:                          34.508   Prob(JB):                         0.00\n",
       "Kurtosis:                    1870.278   Cond. No.                     2.29e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.29e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()\n",
    "# from these random features, there are no notably high p-values. \n",
    "# the r-squared value is low, as might be expected from random features.\n",
    "# we need to develop a good understanding of these metrics, especially p-values,\n",
    "# r-squared and coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test accuracy of the model\n",
    "# to assess accuracy for a regression model (in addition to the r-squared value auto-generated above),\n",
    "# we can find the mean squared error (or root mean squared error)\n",
    "# we could also convert to a classification problem (by setting threshold of popularity and dividing \n",
    "# target into 1 for popular and 0 for unpopular) and then getting the accuracy score from predictions\n",
    "# on a sample from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29733, 59)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     29733.000000\n",
       "mean       3417.181818\n",
       "std       11883.883700\n",
       "min           1.000000\n",
       "25%         944.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reference\n",
    "df_train['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean      3414.867094\n",
       "std       1470.394487\n",
       "min        -32.661669\n",
       "25%       2644.326393\n",
       "50%       3153.067442\n",
       "75%       3912.186534\n",
       "max      26580.254524\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions_sample = df_train[:1000]\n",
    "predictions = lm.predict(train_predictions_sample)\n",
    "predictions.describe()\n",
    "# these predictions are obviously very poor with the current random features model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44570515.599714607"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean squared error\n",
    "mse = mean_squared_error(df_train['shares'][:1000], predictions)\n",
    "mse\n",
    "# something has gone wrong here, obviously. mse is gigantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6676.115307550837"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error for comparison\n",
    "sqrt(mse)\n",
    "# need to understand more about these numbers and discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    604\n",
       "1    396\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn into classification problem and test accuracy score\n",
    "# for now, just using a 3395 shares threshold for classification as popular (above the mean value).  \n",
    "# or could only could extremely high share values as being 'viral' (val 1) and the rest being \n",
    "# 'not viral' (val 0)\n",
    "predictions = predictions.apply(lambda res: 1 if res > 3395 else 0)\n",
    "# calculate predictions for 'shares' on a sample of the set\n",
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martincasey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    23679\n",
       "1     6054\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train['shares_binary'] = df_train['shares'].apply((lambda res: 1 if res > 2800 else 0), axis = 1)\n",
    "# above doesn't work because the single col 'shares' is a series, not a dataframe. axis arg makes no sense\n",
    "# maybe use df_train[['shares']] instead, which should be a dataframe with just one col\n",
    "\n",
    "#df_train['shares_binary'] = df_train[['shares']].apply(lambda res: 1 if res > 3395 else 0)\n",
    "df_train['shares_binary'] = np.where(df_train['shares'] >=3395, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64100000000000001"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_train['shares_binary'][:1000], predictions) \n",
    "# this figure looks not too bad, but it's only predicting membership of the top 25% (if i've dont it right)\n",
    "# look at other thresholds etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[521, 276],\n",
       "       [ 83, 120]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(df_train['shares_binary'][:1000], predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  521 \n",
      "False positives:  276 \n",
      "False negatives:  83 \n",
      "True positives:  120\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ',  fn, '\\nTrue positives: ', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.65      0.74       797\n",
      "          1       0.30      0.59      0.40       203\n",
      "\n",
      "avg / total       0.75      0.64      0.67      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_train['shares_binary'][:1000], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discuss above metrics. repeat with hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     9911.000000\n",
       "mean      3447.463792\n",
       "std       1371.482008\n",
       "min         47.391188\n",
       "25%       2668.745764\n",
       "50%       3167.094040\n",
       "75%       3926.766970\n",
       "max      35178.736616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = lm.predict(df_test)\n",
    "test_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56544275.872000001"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean squared error\n",
    "mse = mean_squared_error(df_test['shares'][:1000], predictions)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7519.592799613553"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mse)\n",
    "rmse\n",
    "# again, this seems like a more realistic figure. look into what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.apply(lambda res: 0 if res<3395 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martincasey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >=3395, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63706992230854609"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test['shares_binary'], test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5090, 2796],\n",
       "       [ 801, 1224]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test['shares_binary'], test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.61      0.70       806\n",
      "          1       0.20      0.42      0.27       194\n",
      "\n",
      "avg / total       0.69      0.57      0.61      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['shares_binary'][:1000], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
