{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, df is created from original dataset\n",
    "# should be replaced by cleaned version once quality plan is complete\n",
    "df = pd.read_csv('OnlineNewsPopularity.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29733.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 75:25 split\n",
    "df.shape[0] * .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle rows of data set and split into training and testing sets\n",
    "# because we have large dataset, cross-validation should not be needed\n",
    "# will use a 75:25 split\n",
    "df = shuffle(df)\n",
    "df_train = df[:29733]\n",
    "df_test = df[29733:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'timedelta', 'n_tokens_title', 'n_tokens_content',\n",
       "       'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens',\n",
       "       'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
       "       'average_token_length', 'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, just a random selection of features. just to lay out the skeleton for a fit\n",
    "lm = sm.ols(formula=\"shares ~ n_tokens_title + num_keywords + kw_avg_avg + title_sentiment_polarity\", data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                  -896.607270\n",
       "n_tokens_title               37.557711\n",
       "num_keywords                114.278407\n",
       "kw_avg_avg                    0.955637\n",
       "title_sentiment_polarity    360.535896\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep in mind the value range for shares when interpreting coefficients, i suppose.\n",
    "# quite different to the 0 or 1 we were dealing with before.\n",
    "df['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th>  <td>   0.015</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.015</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   115.1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>1.29e-97</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:41:15</td>     <th>  Log-Likelihood:    </th> <td>-3.1764e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 29733</td>      <th>  AIC:               </th>  <td>6.353e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 29728</td>      <th>  BIC:               </th>  <td>6.353e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td> -896.6073</td> <td>  409.022</td> <td>   -2.192</td> <td> 0.028</td> <td>-1698.308</td> <td>  -94.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>           <td>   37.5577</td> <td>   28.958</td> <td>    1.297</td> <td> 0.195</td> <td>  -19.202</td> <td>   94.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>             <td>  114.2784</td> <td>   32.069</td> <td>    3.563</td> <td> 0.000</td> <td>   51.421</td> <td>  177.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>               <td>    0.9556</td> <td>    0.046</td> <td>   20.892</td> <td> 0.000</td> <td>    0.866</td> <td>    1.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th> <td>  360.5359</td> <td>  231.464</td> <td>    1.558</td> <td> 0.119</td> <td>  -93.143</td> <td>  814.215</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>80465.111</td> <th>  Durbin-Watson:     </th>    <td>   1.999</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>4809788605.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>33.131</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>1972.262</td>  <th>  Cond. No.          </th>    <td>2.29e+04</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.015\n",
       "Model:                            OLS   Adj. R-squared:                  0.015\n",
       "Method:                 Least Squares   F-statistic:                     115.1\n",
       "Date:                Sun, 22 Apr 2018   Prob (F-statistic):           1.29e-97\n",
       "Time:                        11:41:15   Log-Likelihood:            -3.1764e+05\n",
       "No. Observations:               29733   AIC:                         6.353e+05\n",
       "Df Residuals:                   29728   BIC:                         6.353e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                 -896.6073    409.022     -2.192      0.028   -1698.308     -94.907\n",
       "n_tokens_title              37.5577     28.958      1.297      0.195     -19.202      94.318\n",
       "num_keywords               114.2784     32.069      3.563      0.000      51.421     177.135\n",
       "kw_avg_avg                   0.9556      0.046     20.892      0.000       0.866       1.045\n",
       "title_sentiment_polarity   360.5359    231.464      1.558      0.119     -93.143     814.215\n",
       "==============================================================================\n",
       "Omnibus:                    80465.111   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       4809788605.395\n",
       "Skew:                          33.131   Prob(JB):                         0.00\n",
       "Kurtosis:                    1972.262   Cond. No.                     2.29e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.29e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()\n",
    "# from these random features, there are no notably high p-values. \n",
    "# the r-squared value is low, as might be expected from random features.\n",
    "# we need to develop a good understanding of these metrics, especially p-values,\n",
    "# r-squared and coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy of the model\n",
    "# to assess accuracy for a regression model (in addition to the r-squared value auto-generated above),\n",
    "# we can find the mean squared error (or root mean squared error)\n",
    "# we could also convert to a classification problem (by setting threshold of popularity and dividing \n",
    "# target into 1 for popular and 0 for unpopular) and then getting the accuracy score from predictions\n",
    "# on a sample from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29733, 61)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     29733.000000\n",
       "mean       3345.254196\n",
       "std       10635.041227\n",
       "min          22.000000\n",
       "25%         945.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reference\n",
    "df_train['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean      3354.371556\n",
       "std       1317.541472\n",
       "min        346.412348\n",
       "25%       2618.749461\n",
       "50%       3088.129370\n",
       "75%       3813.469746\n",
       "max      23333.810725\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions_sample = lm.predict(df_train[:1000])\n",
    "train_predictions_sample.describe()\n",
    "# these predictions are obviously very poor with the current random features model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    742\n",
       "1    258\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn into classification problem and test accuracy score\n",
    "# Use a 4542 shares threshold for classification as popular (top 25 %). \n",
    "# or could only could extremely high share values as being 'viral' (val 1) and the rest being \n",
    "# 'not viral' (val 0)\n",
    "train_predictions_sample = train_predictions_sample.apply(lambda res: 1 if res > 3784 else 0)\n",
    "train_predictions_sample.value_counts()\n",
    "# calculate predictions for 'shares' on a sample of the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martincasey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['shares_binary'] = df_train['shares'].apply(lambda res: 1 if res > 3784 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_train['shares_binary'][:1000], train_predictions_sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
