{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Training a linear regression model means estimating a set of weights (one weight per feature, plus an extra weight called the bias or the intercept) on a dataset called the training set.\n",
    "\n",
    "The model estimated is a linear model taking the form:\n",
    "\n",
    "target_feature=w0+w1∗feature1+w2∗feature2+...+wn∗featurentarget_feature=w0+w1∗feature1+w2∗feature2+...+wn∗featuren \n",
    "The learned model can be used to predict the target feature for new examples where we know the descriptive features, but not the target feature. This is called the test example or the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries and packages\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from math import sqrt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reading & shuffling data for linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df is created from original dataset\n",
    "# replaced by cleaned version once quality plan is complete\n",
    "#df = pd.read_csv('OnlineNewsPopularityCleaned.csv', skipinitialspace=True)\n",
    "df = pd.read_csv('OnlineNewsPopularityCleaned.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.050096</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217792</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385        4.0             2.0       1.0         0.0   \n",
       "1                  0.791946        3.0             1.0       1.0         0.0   \n",
       "2                  0.663866        3.0             1.0       1.0         0.0   \n",
       "\n",
       "   average_token_length  num_keywords  data_channel_is_lifestyle  \\\n",
       "0              4.680365           5.0                        0.0   \n",
       "1              4.913725           4.0                        0.0   \n",
       "2              4.393365           6.0                        0.0   \n",
       "\n",
       "   data_channel_is_entertainment  data_channel_is_bus  data_channel_is_socmed  \\\n",
       "0                            1.0                  0.0                     0.0   \n",
       "1                            0.0                  1.0                     0.0   \n",
       "2                            0.0                  1.0                     0.0   \n",
       "\n",
       "   data_channel_is_tech  data_channel_is_world  kw_min_min  kw_max_min  \\\n",
       "0                   0.0                    0.0         0.0         0.0   \n",
       "1                   0.0                    0.0         0.0         0.0   \n",
       "2                   0.0                    0.0         0.0         0.0   \n",
       "\n",
       "   kw_avg_min  kw_min_max  kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   kw_avg_avg  self_reference_min_shares  self_reference_max_shares  \\\n",
       "0         0.0                      496.0                      496.0   \n",
       "1         0.0                        0.0                        0.0   \n",
       "2         0.0                      918.0                      918.0   \n",
       "\n",
       "   self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "0                       496.0                1.0                 0.0   \n",
       "1                         0.0                1.0                 0.0   \n",
       "2                       918.0                1.0                 0.0   \n",
       "\n",
       "   weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "0                   0.0                  0.0                0.0   \n",
       "1                   0.0                  0.0                0.0   \n",
       "2                   0.0                  0.0                0.0   \n",
       "\n",
       "   weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "0                  0.0                0.0         0.0  0.500331  0.378279   \n",
       "1                  0.0                0.0         0.0  0.799756  0.050047   \n",
       "2                  0.0                0.0         0.0  0.217792  0.033334   \n",
       "\n",
       "     LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "0  0.040005  0.041263  0.040123             0.521617   \n",
       "1  0.050096  0.050101  0.050001             0.341246   \n",
       "2  0.033351  0.033334  0.682188             0.702222   \n",
       "\n",
       "   global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0                   0.092562                    0.045662   \n",
       "1                   0.148948                    0.043137   \n",
       "2                   0.323333                    0.056872   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.015686             0.733333             0.266667   \n",
       "2                    0.009479             0.857143             0.142857   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.286915               0.033333                    0.7   \n",
       "2               0.495833               0.100000                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                 -0.600              -0.200000   \n",
       "1              -0.118750                 -0.125              -0.100000   \n",
       "2              -0.466667                 -0.800              -0.133333   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 0.5                   -0.1875                     0.0   \n",
       "1                 0.0                    0.0000                     0.5   \n",
       "2                 0.0                    0.0000                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                        0.1875     593  \n",
       "1                        0.0000     711  \n",
       "2                        0.0000    1500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print (rows, columns)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a 39644 articles in our dataframe, with 33 features associated with each individual article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Print the first and the last 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.050096</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217792</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.494651</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.429850</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>3151.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.028794</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "3             9.0             531.0         0.503788               1.0   \n",
       "4            13.0            1072.0         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385        4.0             2.0       1.0         0.0   \n",
       "1                  0.791946        3.0             1.0       1.0         0.0   \n",
       "2                  0.663866        3.0             1.0       1.0         0.0   \n",
       "3                  0.665635        9.0             0.0       1.0         0.0   \n",
       "4                  0.540890       19.0            19.0      20.0         0.0   \n",
       "\n",
       "   average_token_length  num_keywords  data_channel_is_lifestyle  \\\n",
       "0              4.680365           5.0                        0.0   \n",
       "1              4.913725           4.0                        0.0   \n",
       "2              4.393365           6.0                        0.0   \n",
       "3              4.404896           7.0                        0.0   \n",
       "4              4.682836           7.0                        0.0   \n",
       "\n",
       "   data_channel_is_entertainment  data_channel_is_bus  data_channel_is_socmed  \\\n",
       "0                            1.0                  0.0                     0.0   \n",
       "1                            0.0                  1.0                     0.0   \n",
       "2                            0.0                  1.0                     0.0   \n",
       "3                            1.0                  0.0                     0.0   \n",
       "4                            0.0                  0.0                     0.0   \n",
       "\n",
       "   data_channel_is_tech  data_channel_is_world  kw_min_min  kw_max_min  \\\n",
       "0                   0.0                    0.0         0.0         0.0   \n",
       "1                   0.0                    0.0         0.0         0.0   \n",
       "2                   0.0                    0.0         0.0         0.0   \n",
       "3                   0.0                    0.0         0.0         0.0   \n",
       "4                   1.0                    0.0         0.0         0.0   \n",
       "\n",
       "   kw_avg_min  kw_min_max  kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   kw_avg_avg  self_reference_min_shares  self_reference_max_shares  \\\n",
       "0         0.0                      496.0                      496.0   \n",
       "1         0.0                        0.0                        0.0   \n",
       "2         0.0                      918.0                      918.0   \n",
       "3         0.0                        0.0                        0.0   \n",
       "4         0.0                      545.0                    16000.0   \n",
       "\n",
       "   self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "0                  496.000000                1.0                 0.0   \n",
       "1                    0.000000                1.0                 0.0   \n",
       "2                  918.000000                1.0                 0.0   \n",
       "3                    0.000000                1.0                 0.0   \n",
       "4                 3151.157895                1.0                 0.0   \n",
       "\n",
       "   weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "0                   0.0                  0.0                0.0   \n",
       "1                   0.0                  0.0                0.0   \n",
       "2                   0.0                  0.0                0.0   \n",
       "3                   0.0                  0.0                0.0   \n",
       "4                   0.0                  0.0                0.0   \n",
       "\n",
       "   weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "0                  0.0                0.0         0.0  0.500331  0.378279   \n",
       "1                  0.0                0.0         0.0  0.799756  0.050047   \n",
       "2                  0.0                0.0         0.0  0.217792  0.033334   \n",
       "3                  0.0                0.0         0.0  0.028573  0.419300   \n",
       "4                  0.0                0.0         0.0  0.028633  0.028794   \n",
       "\n",
       "     LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "0  0.040005  0.041263  0.040123             0.521617   \n",
       "1  0.050096  0.050101  0.050001             0.341246   \n",
       "2  0.033351  0.033334  0.682188             0.702222   \n",
       "3  0.494651  0.028905  0.028572             0.429850   \n",
       "4  0.028575  0.028572  0.885427             0.513502   \n",
       "\n",
       "   global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0                   0.092562                    0.045662   \n",
       "1                   0.148948                    0.043137   \n",
       "2                   0.323333                    0.056872   \n",
       "3                   0.100705                    0.041431   \n",
       "4                   0.281003                    0.074627   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.015686             0.733333             0.266667   \n",
       "2                    0.009479             0.857143             0.142857   \n",
       "3                    0.020716             0.666667             0.333333   \n",
       "4                    0.012127             0.860215             0.139785   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.286915               0.033333                    0.7   \n",
       "2               0.495833               0.100000                    1.0   \n",
       "3               0.385965               0.136364                    0.8   \n",
       "4               0.411127               0.033333                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                 -0.600              -0.200000   \n",
       "1              -0.118750                 -0.125              -0.100000   \n",
       "2              -0.466667                 -0.800              -0.133333   \n",
       "3              -0.369697                 -0.600              -0.166667   \n",
       "4              -0.220192                 -0.500              -0.050000   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                 -0.187500                0.000000   \n",
       "1            0.000000                  0.000000                0.500000   \n",
       "2            0.000000                  0.000000                0.500000   \n",
       "3            0.000000                  0.000000                0.500000   \n",
       "4            0.454545                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500     593  \n",
       "1                      0.000000     711  \n",
       "2                      0.000000    1500  \n",
       "3                      0.000000    1200  \n",
       "4                      0.136364     505  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38458</th>\n",
       "      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.523121</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>173.125</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>374962.500000</td>\n",
       "      <td>2514.742857</td>\n",
       "      <td>4004.342857</td>\n",
       "      <td>3031.115764</td>\n",
       "      <td>11400.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>37033.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025038</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.151701</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.482679</td>\n",
       "      <td>0.141964</td>\n",
       "      <td>0.037572</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38459</th>\n",
       "      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.405488</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>184.000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>192985.714286</td>\n",
       "      <td>1664.267857</td>\n",
       "      <td>5470.168651</td>\n",
       "      <td>3411.660830</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.681635</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.564374</td>\n",
       "      <td>0.194249</td>\n",
       "      <td>0.039634</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.374825</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38460</th>\n",
       "      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>168.250</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>295850.000000</td>\n",
       "      <td>1753.882353</td>\n",
       "      <td>6880.687034</td>\n",
       "      <td>4206.439195</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159004</td>\n",
       "      <td>0.025025</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.146970</td>\n",
       "      <td>0.510296</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.307273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38461</th>\n",
       "      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.975073</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>254600.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3384.316871</td>\n",
       "      <td>1777.895883</td>\n",
       "      <td>452.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.358578</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.236851</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38462</th>\n",
       "      <td>http://mashable.com/2014/12/27/youtube-channel...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.471338</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.500</td>\n",
       "      <td>205600.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>366200.000000</td>\n",
       "      <td>3035.080555</td>\n",
       "      <td>3613.512953</td>\n",
       "      <td>3296.909481</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.799339</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050659</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.104892</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.247338</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  timedelta  \\\n",
       "38458  http://mashable.com/2014/12/27/samsung-app-aut...        8.0   \n",
       "38459  http://mashable.com/2014/12/27/seth-rogen-jame...        8.0   \n",
       "38460  http://mashable.com/2014/12/27/son-pays-off-mo...        8.0   \n",
       "38461     http://mashable.com/2014/12/27/ukraine-blasts/        8.0   \n",
       "38462  http://mashable.com/2014/12/27/youtube-channel...        8.0   \n",
       "\n",
       "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "38458            11.0             346.0         0.529052               1.0   \n",
       "38459            12.0             328.0         0.696296               1.0   \n",
       "38460            10.0             442.0         0.516355               1.0   \n",
       "38461             6.0             682.0         0.539493               1.0   \n",
       "38462            10.0             157.0         0.701987               1.0   \n",
       "\n",
       "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  \\\n",
       "38458                  0.684783        9.0             7.0       1.0   \n",
       "38459                  0.885057        9.0             7.0       3.0   \n",
       "38460                  0.644128       24.0             1.0      12.0   \n",
       "38461                  0.692661       10.0             1.0       1.0   \n",
       "38462                  0.846154        1.0             1.0       0.0   \n",
       "\n",
       "       num_videos  average_token_length  num_keywords  \\\n",
       "38458         1.0              4.523121           8.0   \n",
       "38459        48.0              4.405488           7.0   \n",
       "38460         1.0              5.076923           8.0   \n",
       "38461         0.0              4.975073           5.0   \n",
       "38462         2.0              4.471338           4.0   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "38458                        0.0                            0.0   \n",
       "38459                        0.0                            0.0   \n",
       "38460                        0.0                            0.0   \n",
       "38461                        0.0                            0.0   \n",
       "38462                        0.0                            1.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "38458                  0.0                     0.0                   1.0   \n",
       "38459                  0.0                     1.0                   0.0   \n",
       "38460                  0.0                     0.0                   0.0   \n",
       "38461                  0.0                     0.0                   0.0   \n",
       "38462                  0.0                     0.0                   0.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "38458                    0.0        -1.0       671.0     173.125     26900.0   \n",
       "38459                    0.0        -1.0       616.0     184.000      6500.0   \n",
       "38460                    0.0        -1.0       691.0     168.250      6200.0   \n",
       "38461                    1.0        -1.0         0.0      -1.000         0.0   \n",
       "38462                    0.0        -1.0        97.0      23.500    205600.0   \n",
       "\n",
       "       kw_max_max     kw_avg_max   kw_min_avg   kw_max_avg   kw_avg_avg  \\\n",
       "38458    843300.0  374962.500000  2514.742857  4004.342857  3031.115764   \n",
       "38459    843300.0  192985.714286  1664.267857  5470.168651  3411.660830   \n",
       "38460    843300.0  295850.000000  1753.882353  6880.687034  4206.439195   \n",
       "38461    843300.0  254600.000000     0.000000  3384.316871  1777.895883   \n",
       "38462    843300.0  366200.000000  3035.080555  3613.512953  3296.909481   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "38458                    11400.0                    48000.0   \n",
       "38459                     2100.0                     2100.0   \n",
       "38460                     1400.0                     1400.0   \n",
       "38461                      452.0                      452.0   \n",
       "38462                     2100.0                     2100.0   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "38458                37033.333333                0.0                 0.0   \n",
       "38459                 2100.000000                0.0                 0.0   \n",
       "38460                 1400.000000                0.0                 0.0   \n",
       "38461                  452.000000                0.0                 0.0   \n",
       "38462                 2100.000000                0.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "38458                   1.0                  0.0                0.0   \n",
       "38459                   1.0                  0.0                0.0   \n",
       "38460                   1.0                  0.0                0.0   \n",
       "38461                   1.0                  0.0                0.0   \n",
       "38462                   1.0                  0.0                0.0   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "38458                  0.0                0.0         0.0  0.025038  0.025001   \n",
       "38459                  0.0                0.0         0.0  0.029349  0.028575   \n",
       "38460                  0.0                0.0         0.0  0.159004  0.025025   \n",
       "38461                  0.0                0.0         0.0  0.040004  0.040003   \n",
       "38462                  0.0                0.0         0.0  0.050001  0.799339   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "38458  0.151701  0.025000  0.773260             0.482679   \n",
       "38459  0.231866  0.681635  0.028575             0.564374   \n",
       "38460  0.025207  0.643794  0.146970             0.510296   \n",
       "38461  0.839987  0.040002  0.040004             0.358578   \n",
       "38462  0.050000  0.050659  0.050001             0.517893   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "38458                   0.141964                    0.037572   \n",
       "38459                   0.194249                    0.039634   \n",
       "38460                   0.024609                    0.033937   \n",
       "38461                  -0.008066                    0.020528   \n",
       "38462                   0.104892                    0.063694   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "38458                    0.014451             0.722222             0.277778   \n",
       "38459                    0.009146             0.812500             0.187500   \n",
       "38460                    0.024887             0.576923             0.423077   \n",
       "38461                    0.023460             0.466667             0.533333   \n",
       "38462                    0.012739             0.833333             0.166667   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "38458               0.333791               0.100000                   0.75   \n",
       "38459               0.374825               0.136364                   0.70   \n",
       "38460               0.307273               0.136364                   0.50   \n",
       "38461               0.236851               0.062500                   0.50   \n",
       "38462               0.247338               0.100000                   0.50   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "38458              -0.260000                   -0.5              -0.125000   \n",
       "38459              -0.211111                   -0.4              -0.100000   \n",
       "38460              -0.356439                   -0.8              -0.166667   \n",
       "38461              -0.205246                   -0.5              -0.012500   \n",
       "38462              -0.200000                   -0.2              -0.200000   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "38458            0.100000                  0.000000                0.400000   \n",
       "38459            0.300000                  1.000000                0.200000   \n",
       "38460            0.454545                  0.136364                0.045455   \n",
       "38461            0.000000                  0.000000                0.500000   \n",
       "38462            0.333333                  0.250000                0.166667   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "38458                      0.000000    1800  \n",
       "38459                      1.000000    1900  \n",
       "38460                      0.136364    1900  \n",
       "38461                      0.000000    1100  \n",
       "38462                      0.250000    1300  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38463, 61)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the data and splitting it for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>568.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.065116</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>363.833333</td>\n",
       "      <td>938.0</td>\n",
       "      <td>690400.0</td>\n",
       "      <td>137023.000000</td>\n",
       "      <td>938.0</td>\n",
       "      <td>3278.649419</td>\n",
       "      <td>2279.969247</td>\n",
       "      <td>997.0</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3898.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.865481</td>\n",
       "      <td>0.033746</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.464556</td>\n",
       "      <td>0.113149</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.383117</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.508333</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13479</th>\n",
       "      <td>470.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.950820</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>354.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>317042.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32180.000000</td>\n",
       "      <td>8511.344229</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.513509</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.400774</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>388.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.331606</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>198885.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3470.212122</td>\n",
       "      <td>2329.799441</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>2366.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.399074</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.515201</td>\n",
       "      <td>0.353704</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "8543       568.0             7.0             215.0         0.674528   \n",
       "13479      470.0            10.0             183.0         0.548023   \n",
       "17500      388.0             7.0             193.0         0.610169   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "8543                1.0                  0.826087        4.0             3.0   \n",
       "13479               1.0                  0.563910        9.0             4.0   \n",
       "17500               1.0                  0.786408        6.0             4.0   \n",
       "\n",
       "       num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "8543        0.0         1.0              5.065116           6.0   \n",
       "13479      12.0         0.0              4.950820           7.0   \n",
       "17500       1.0         0.0              4.331606           7.0   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "8543                         0.0                            0.0   \n",
       "13479                        0.0                            0.0   \n",
       "17500                        0.0                            0.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "8543                   0.0                     0.0                   0.0   \n",
       "13479                  0.0                     0.0                   0.0   \n",
       "17500                  0.0                     0.0                   1.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "8543                     1.0         4.0       938.0  363.833333       938.0   \n",
       "13479                    0.0         4.0      1000.0  354.666667         0.0   \n",
       "17500                    0.0        -1.0       531.0  210.000000         0.0   \n",
       "\n",
       "       kw_max_max     kw_avg_max  kw_min_avg    kw_max_avg   kw_avg_avg  \\\n",
       "8543     690400.0  137023.000000       938.0   3278.649419  2279.969247   \n",
       "13479    843300.0  317042.857143         0.0  32180.000000  8511.344229   \n",
       "17500    843300.0  198885.714286         0.0   3470.212122  2329.799441   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "8543                       997.0                     6800.0   \n",
       "13479                     3900.0                     3900.0   \n",
       "17500                     1800.0                     3500.0   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "8543                  3898.500000                0.0                 0.0   \n",
       "13479                 3900.000000                0.0                 0.0   \n",
       "17500                 2366.666667                1.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "8543                    1.0                  0.0                0.0   \n",
       "13479                   1.0                  0.0                0.0   \n",
       "17500                   0.0                  0.0                0.0   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "8543                   0.0                0.0         0.0  0.034037  0.033400   \n",
       "13479                  0.0                0.0         0.0  0.028573  0.513509   \n",
       "17500                  0.0                0.0         0.0  0.028576  0.399074   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "8543   0.865481  0.033746  0.033335             0.464556   \n",
       "13479  0.028572  0.400774  0.028572             0.644444   \n",
       "17500  0.028575  0.028574  0.515201             0.353704   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "8543                    0.113149                    0.051163   \n",
       "13479                   0.233333                    0.027322   \n",
       "17500                   0.072222                    0.020725   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "8543                     0.013953             0.785714             0.214286   \n",
       "13479                    0.005464             0.833333             0.166667   \n",
       "17500                    0.010363             0.666667             0.333333   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "8543                0.383117                    0.2                   0.90   \n",
       "13479               0.520000                    0.1                   0.80   \n",
       "17500               0.237500                    0.1                   0.35   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "8543               -0.508333                 -0.875                  -0.25   \n",
       "13479              -0.600000                 -0.600                  -0.60   \n",
       "17500              -0.150000                 -0.200                  -0.10   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "8543             0.950000                       0.3                0.450000   \n",
       "13479            0.666667                      -0.7                0.166667   \n",
       "17500            0.000000                       0.0                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "8543                            0.3    1900  \n",
       "13479                           0.7   25100  \n",
       "17500                           0.0     939  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffle=shuffle(df)\n",
    "df_shuffle.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26924"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#70% of data value is being saved in variable a\n",
    "a=int(df_shuffle.shape[0]*0.7)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11539"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#70% of data value is being saved in variable b\n",
    "b=df_shuffle.shape[0]-int(df_shuffle.shape[0]*0.7)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=df_shuffle.head(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=df_shuffle.head(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>568.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.065116</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>363.833333</td>\n",
       "      <td>938.0</td>\n",
       "      <td>690400.0</td>\n",
       "      <td>137023.000000</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>3278.649419</td>\n",
       "      <td>2279.969247</td>\n",
       "      <td>997.0</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3898.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.865481</td>\n",
       "      <td>0.033746</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.464556</td>\n",
       "      <td>0.113149</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.383117</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.508333</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13479</th>\n",
       "      <td>470.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.950820</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>354.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>317042.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32180.000000</td>\n",
       "      <td>8511.344229</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.513509</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.400774</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>25100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>388.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.331606</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>198885.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3470.212122</td>\n",
       "      <td>2329.799441</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>2366.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.399074</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.515201</td>\n",
       "      <td>0.353704</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>707.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0.565574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719472</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>27742.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3809.000000</td>\n",
       "      <td>2050.220649</td>\n",
       "      <td>294.0</td>\n",
       "      <td>26600.0</td>\n",
       "      <td>7448.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456845</td>\n",
       "      <td>0.300320</td>\n",
       "      <td>0.184892</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.546276</td>\n",
       "      <td>0.168970</td>\n",
       "      <td>0.059184</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.384834</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.339444</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14432</th>\n",
       "      <td>451.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>0.516295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.696275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.452261</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>209.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>166850.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3262.749031</td>\n",
       "      <td>1863.753086</td>\n",
       "      <td>527.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>2603.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025048</td>\n",
       "      <td>0.025261</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.899687</td>\n",
       "      <td>0.450707</td>\n",
       "      <td>0.173421</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.364432</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.244444</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>692.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.691860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.895349</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>629.857143</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>29428.571429</td>\n",
       "      <td>2321.806452</td>\n",
       "      <td>5850.000000</td>\n",
       "      <td>3304.554875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.028617</td>\n",
       "      <td>0.028650</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.173414</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198187</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34892</th>\n",
       "      <td>71.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.917706</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>365.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>172928.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3446.075532</td>\n",
       "      <td>2308.316202</td>\n",
       "      <td>672.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.028648</td>\n",
       "      <td>0.212360</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>0.701800</td>\n",
       "      <td>0.566074</td>\n",
       "      <td>0.092315</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.022444</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.485897</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.355247</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13561</th>\n",
       "      <td>469.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>0.497253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715373</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.581189</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>109.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>189300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3266.698581</td>\n",
       "      <td>2414.624061</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025019</td>\n",
       "      <td>0.025527</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>0.524290</td>\n",
       "      <td>0.400103</td>\n",
       "      <td>0.512122</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>0.058563</td>\n",
       "      <td>0.034605</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.382165</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.304879</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>693.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.587963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.726027</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>322.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>35942.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4641.818182</td>\n",
       "      <td>2535.043909</td>\n",
       "      <td>15700.0</td>\n",
       "      <td>15700.0</td>\n",
       "      <td>15700.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028629</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.885618</td>\n",
       "      <td>0.515377</td>\n",
       "      <td>0.106453</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.264035</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.450000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38019</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>0.418367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629423</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.737903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>139.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>233500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3393.367028</td>\n",
       "      <td>1834.280723</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.885708</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.482792</td>\n",
       "      <td>0.185725</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.376582</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.221991</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "8543       568.0             7.0             215.0         0.674528   \n",
       "13479      470.0            10.0             183.0         0.548023   \n",
       "17500      388.0             7.0             193.0         0.610169   \n",
       "1445       707.0            10.0             490.0         0.565574   \n",
       "14432      451.0             9.0             597.0         0.516295   \n",
       "2315       692.0            10.0             172.0         0.691860   \n",
       "34892       71.0            13.0             401.0         0.555276   \n",
       "13561      469.0            10.0            1127.0         0.497253   \n",
       "2270       693.0             9.0             219.0         0.587963   \n",
       "38019       20.0            12.0             992.0         0.418367   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "8543                1.0                  0.826087        4.0             3.0   \n",
       "13479               1.0                  0.563910        9.0             4.0   \n",
       "17500               1.0                  0.786408        6.0             4.0   \n",
       "1445                1.0                  0.719472       11.0             8.0   \n",
       "14432               1.0                  0.696275       10.0            10.0   \n",
       "2315                1.0                  0.782609        4.0             3.0   \n",
       "34892               1.0                  0.758929        2.0             1.0   \n",
       "13561               1.0                  0.715373       16.0             6.0   \n",
       "2270                1.0                  0.707692        2.0             2.0   \n",
       "38019               1.0                  0.629423        2.0             1.0   \n",
       "\n",
       "       num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "8543        0.0         1.0              5.065116           6.0   \n",
       "13479      12.0         0.0              4.950820           7.0   \n",
       "17500       1.0         0.0              4.331606           7.0   \n",
       "1445        1.0         0.0              4.700000           7.0   \n",
       "14432       1.0         0.0              4.452261           8.0   \n",
       "2315        1.0         0.0              4.895349           7.0   \n",
       "34892       1.0         2.0              4.917706           7.0   \n",
       "13561      11.0         0.0              4.581189           8.0   \n",
       "2270        1.0         0.0              4.726027           7.0   \n",
       "38019       1.0         1.0              4.737903           7.0   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "8543                         0.0                            0.0   \n",
       "13479                        0.0                            0.0   \n",
       "17500                        0.0                            0.0   \n",
       "1445                         0.0                            1.0   \n",
       "14432                        0.0                            0.0   \n",
       "2315                         0.0                            0.0   \n",
       "34892                        0.0                            0.0   \n",
       "13561                        0.0                            0.0   \n",
       "2270                         1.0                            0.0   \n",
       "38019                        0.0                            0.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "8543                   0.0                     0.0                   0.0   \n",
       "13479                  0.0                     0.0                   0.0   \n",
       "17500                  0.0                     0.0                   1.0   \n",
       "1445                   0.0                     0.0                   0.0   \n",
       "14432                  0.0                     0.0                   1.0   \n",
       "2315                   0.0                     1.0                   0.0   \n",
       "34892                  0.0                     0.0                   0.0   \n",
       "13561                  0.0                     0.0                   1.0   \n",
       "2270                   0.0                     0.0                   0.0   \n",
       "38019                  0.0                     0.0                   0.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "8543                     1.0         4.0       938.0  363.833333       938.0   \n",
       "13479                    0.0         4.0      1000.0  354.666667         0.0   \n",
       "17500                    0.0        -1.0       531.0  210.000000         0.0   \n",
       "1445                     0.0       217.0       792.0  401.000000         0.0   \n",
       "14432                    0.0         4.0       531.0  209.166667         0.0   \n",
       "2315                     0.0       217.0      1300.0  629.857143      3600.0   \n",
       "34892                    1.0        -1.0       973.0  365.666667         0.0   \n",
       "13561                    0.0         4.0       331.0  109.857143         0.0   \n",
       "2270                     0.0       217.0       456.0  322.500000         0.0   \n",
       "38019                    1.0        -1.0       843.0  139.666667         0.0   \n",
       "\n",
       "       kw_max_max     kw_avg_max   kw_min_avg    kw_max_avg   kw_avg_avg  \\\n",
       "8543     690400.0  137023.000000   938.000000   3278.649419  2279.969247   \n",
       "13479    843300.0  317042.857143     0.000000  32180.000000  8511.344229   \n",
       "17500    843300.0  198885.714286     0.000000   3470.212122  2329.799441   \n",
       "1445      69100.0   27742.857143     0.000000   3809.000000  2050.220649   \n",
       "14432    843300.0  166850.000000     0.000000   3262.749031  1863.753086   \n",
       "2315      69100.0   29428.571429  2321.806452   5850.000000  3304.554875   \n",
       "34892    843300.0  172928.571429     0.000000   3446.075532  2308.316202   \n",
       "13561    843300.0  189300.000000     0.000000   3266.698581  2414.624061   \n",
       "2270      69100.0   35942.857143     0.000000   4641.818182  2535.043909   \n",
       "38019    843300.0  233500.000000     0.000000   3393.367028  1834.280723   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "8543                       997.0                     6800.0   \n",
       "13479                     3900.0                     3900.0   \n",
       "17500                     1800.0                     3500.0   \n",
       "1445                       294.0                    26600.0   \n",
       "14432                      527.0                     7900.0   \n",
       "2315                         0.0                        0.0   \n",
       "34892                      672.0                      672.0   \n",
       "13561                     2700.0                     2700.0   \n",
       "2270                     15700.0                    15700.0   \n",
       "38019                     2100.0                     2100.0   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "8543                  3898.500000                0.0                 0.0   \n",
       "13479                 3900.000000                0.0                 0.0   \n",
       "17500                 2366.666667                1.0                 0.0   \n",
       "1445                  7448.500000                0.0                 0.0   \n",
       "14432                 2603.857143                1.0                 0.0   \n",
       "2315                     0.000000                0.0                 0.0   \n",
       "34892                  672.000000                0.0                 0.0   \n",
       "13561                 2700.000000                0.0                 0.0   \n",
       "2270                 15700.000000                0.0                 0.0   \n",
       "38019                 2100.000000                0.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "8543                    1.0                  0.0                0.0   \n",
       "13479                   1.0                  0.0                0.0   \n",
       "17500                   0.0                  0.0                0.0   \n",
       "1445                    0.0                  1.0                0.0   \n",
       "14432                   0.0                  0.0                0.0   \n",
       "2315                    0.0                  0.0                1.0   \n",
       "34892                   1.0                  0.0                0.0   \n",
       "13561                   0.0                  1.0                0.0   \n",
       "2270                    0.0                  1.0                0.0   \n",
       "38019                   0.0                  0.0                1.0   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "8543                   0.0                0.0         0.0  0.034037  0.033400   \n",
       "13479                  0.0                0.0         0.0  0.028573  0.513509   \n",
       "17500                  0.0                0.0         0.0  0.028576  0.399074   \n",
       "1445                   0.0                0.0         0.0  0.456845  0.300320   \n",
       "14432                  0.0                0.0         0.0  0.025048  0.025261   \n",
       "2315                   0.0                0.0         0.0  0.884956  0.028617   \n",
       "34892                  0.0                0.0         0.0  0.028574  0.028648   \n",
       "13561                  0.0                0.0         0.0  0.025019  0.025527   \n",
       "2270                   0.0                0.0         0.0  0.028629  0.028575   \n",
       "38019                  0.0                0.0         0.0  0.028573  0.028573   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "8543   0.865481  0.033746  0.033335             0.464556   \n",
       "13479  0.028572  0.400774  0.028572             0.644444   \n",
       "17500  0.028575  0.028574  0.515201             0.353704   \n",
       "1445   0.184892  0.029371  0.028572             0.546276   \n",
       "14432  0.025002  0.025002  0.899687             0.450707   \n",
       "2315   0.028650  0.028755  0.029021             0.331818   \n",
       "34892  0.212360  0.028618  0.701800             0.566074   \n",
       "13561  0.025061  0.524290  0.400103             0.512122   \n",
       "2270   0.028574  0.028604  0.885618             0.515377   \n",
       "38019  0.885708  0.028572  0.028573             0.482792   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "8543                    0.113149                    0.051163   \n",
       "13479                   0.233333                    0.027322   \n",
       "17500                   0.072222                    0.020725   \n",
       "1445                    0.168970                    0.059184   \n",
       "14432                   0.173421                    0.050251   \n",
       "2315                    0.173414                    0.081395   \n",
       "34892                   0.092315                    0.032419   \n",
       "13561                   0.099175                    0.058563   \n",
       "2270                    0.106453                    0.045662   \n",
       "38019                   0.185725                    0.042339   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "8543                     0.013953             0.785714             0.214286   \n",
       "13479                    0.005464             0.833333             0.166667   \n",
       "17500                    0.010363             0.666667             0.333333   \n",
       "1445                     0.020408             0.743590             0.256410   \n",
       "14432                    0.010050             0.833333             0.166667   \n",
       "2315                     0.000000             1.000000             0.000000   \n",
       "34892                    0.022444             0.590909             0.409091   \n",
       "13561                    0.034605             0.628571             0.371429   \n",
       "2270                     0.009132             0.833333             0.166667   \n",
       "38019                    0.012097             0.777778             0.222222   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "8543                0.383117               0.200000                   0.90   \n",
       "13479               0.520000               0.100000                   0.80   \n",
       "17500               0.237500               0.100000                   0.35   \n",
       "1445                0.384834               0.100000                   1.00   \n",
       "14432               0.364432               0.050000                   0.80   \n",
       "2315                0.198187               0.033333                   0.50   \n",
       "34892               0.485897               0.100000                   1.00   \n",
       "13561               0.382165               0.062500                   1.00   \n",
       "2270                0.264035               0.136364                   0.50   \n",
       "38019               0.376582               0.050000                   1.00   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "8543               -0.508333                 -0.875                 -0.250   \n",
       "13479              -0.600000                 -0.600                 -0.600   \n",
       "17500              -0.150000                 -0.200                 -0.100   \n",
       "1445               -0.339444                 -0.800                 -0.050   \n",
       "14432              -0.244444                 -0.700                 -0.050   \n",
       "2315                0.000000                  0.000                  0.000   \n",
       "34892              -0.355247                 -0.900                 -0.100   \n",
       "13561              -0.304879                 -0.700                 -0.050   \n",
       "2270               -0.450000                 -0.600                 -0.300   \n",
       "38019              -0.221991                 -0.400                 -0.075   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "8543             0.950000                  0.300000                0.450000   \n",
       "13479            0.666667                 -0.700000                0.166667   \n",
       "17500            0.000000                  0.000000                0.500000   \n",
       "1445             0.000000                 -0.200000                0.500000   \n",
       "14432            0.900000                  0.400000                0.400000   \n",
       "2315             0.066667                  0.033333                0.433333   \n",
       "34892            0.000000                  0.000000                0.500000   \n",
       "13561            0.000000                  0.000000                0.500000   \n",
       "2270             0.454545                  0.136364                0.045455   \n",
       "38019            1.000000                  0.500000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "8543                       0.300000    1900  \n",
       "13479                      0.700000   25100  \n",
       "17500                      0.000000     939  \n",
       "1445                       0.200000     380  \n",
       "14432                      0.400000    1600  \n",
       "2315                       0.033333    4800  \n",
       "34892                      0.000000    1500  \n",
       "13561                      0.000000    2400  \n",
       "2270                       0.136364    1500  \n",
       "38019                      0.500000     957  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Data using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## a. All the features\n",
    "\n",
    "Evaluating the quality of the model on all the features\n",
    "\n",
    "### Training the model with all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                         -350.299442\n",
      "n_tokens_title                      79.818573\n",
      "n_tokens_content                     0.608371\n",
      "n_unique_tokens                   3925.777602\n",
      "n_non_stop_words                 -1580.075084\n",
      "n_non_stop_unique_tokens         -1692.035733\n",
      "num_hrefs                           26.566286\n",
      "num_self_hrefs                     -56.702242\n",
      "num_imgs                             8.475340\n",
      "num_videos                           4.796970\n",
      "average_token_length              -572.669340\n",
      "num_keywords                        47.421483\n",
      "data_channel_is_lifestyle        -1089.104347\n",
      "data_channel_is_entertainment    -1201.842877\n",
      "data_channel_is_bus               -815.086471\n",
      "data_channel_is_socmed            -626.961134\n",
      "data_channel_is_tech              -578.256824\n",
      "data_channel_is_world             -555.686434\n",
      "kw_min_min                           2.253979\n",
      "kw_max_min                           0.088990\n",
      "kw_avg_min                          -0.368438\n",
      "kw_min_max                          -0.001984\n",
      "kw_max_max                          -0.000488\n",
      "kw_avg_max                          -0.000752\n",
      "kw_min_avg                          -0.384648\n",
      "kw_max_avg                          -0.204222\n",
      "kw_avg_avg                           1.673241\n",
      "self_reference_min_shares            0.026116\n",
      "self_reference_max_shares            0.005737\n",
      "self_reference_avg_sharess          -0.005702\n",
      "weekday_is_monday                  280.140846\n",
      "weekday_is_tuesday                -248.014845\n",
      "weekday_is_wednesday               -46.928513\n",
      "weekday_is_thursday               -246.862712\n",
      "weekday_is_friday                 -229.894011\n",
      "weekday_is_saturday                277.353196\n",
      "weekday_is_sunday                 -136.093404\n",
      "is_weekend                         141.259792\n",
      "LDA_00                             496.516307\n",
      "LDA_01                            -276.005243\n",
      "LDA_02                            -737.108053\n",
      "LDA_03                              95.706728\n",
      "LDA_04                              71.772160\n",
      "global_subjectivity               2439.470236\n",
      "global_sentiment_polarity          735.044503\n",
      "global_rate_positive_words      -13908.186679\n",
      "global_rate_negative_words        1317.435969\n",
      "rate_positive_words               2124.231172\n",
      "rate_negative_words               2057.971041\n",
      "avg_positive_polarity            -1632.259876\n",
      "min_positive_polarity            -1981.236316\n",
      "max_positive_polarity              346.289781\n",
      "avg_negative_polarity            -1669.850234\n",
      "min_negative_polarity              115.220658\n",
      "max_negative_polarity             -210.526776\n",
      "title_subjectivity                -100.036323\n",
      "title_sentiment_polarity           139.894225\n",
      "abs_title_subjectivity             509.403288\n",
      "abs_title_sentiment_polarity       682.662938\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Import statsmodels package for training a linear regression model.\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# The formula specifies the target feature and the descriptive features used for training the \n",
    "# linear regression model.\n",
    "# We first train a simple linear regression with only one descriptive feature (Size).\n",
    "# For training the model we call the method fit() on the given data stored in our df dataframe.\n",
    "lm_a = sm.ols(formula=\"shares ~ n_tokens_title+n_tokens_content+n_unique_tokens+n_non_stop_words+n_non_stop_unique_tokens+num_hrefs+num_self_hrefs+num_imgs+num_videos+average_token_length+num_keywords+data_channel_is_lifestyle+data_channel_is_entertainment+data_channel_is_bus+data_channel_is_socmed+data_channel_is_tech+data_channel_is_world+kw_min_min+kw_max_min+kw_avg_min+kw_min_max+kw_max_max+kw_avg_max+kw_min_avg+kw_max_avg+kw_avg_avg+self_reference_min_shares+self_reference_max_shares+self_reference_avg_sharess+weekday_is_monday+weekday_is_tuesday+weekday_is_wednesday+weekday_is_thursday+weekday_is_friday+weekday_is_saturday+weekday_is_sunday+is_weekend+LDA_00+LDA_01+LDA_02+LDA_03+LDA_04+global_subjectivity+global_sentiment_polarity+global_rate_positive_words+global_rate_negative_words+rate_positive_words+rate_negative_words+avg_positive_polarity+min_positive_polarity+max_positive_polarity+avg_negative_polarity+min_negative_polarity+max_negative_polarity+title_subjectivity+title_sentiment_polarity+abs_title_subjectivity+abs_title_sentiment_polarity\", data=df).fit()\n",
    "# Print the model weights/parameters\n",
    "print(lm_a.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the quality of the model on all data (p-values, R-squared)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 shares   R-squared:                       0.023\n",
      "Model:                            OLS   Adj. R-squared:                  0.021\n",
      "Method:                 Least Squares   F-statistic:                     16.35\n",
      "Date:                Mon, 30 Apr 2018   Prob (F-statistic):          5.91e-151\n",
      "Time:                        11:42:50   Log-Likelihood:            -4.1405e+05\n",
      "No. Observations:               38463   AIC:                         8.282e+05\n",
      "Df Residuals:                   38407   BIC:                         8.287e+05\n",
      "Df Model:                          55                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                      -350.2994   4283.654     -0.082      0.935   -8746.371    8045.772\n",
      "n_tokens_title                   79.8186     29.008      2.752      0.006      22.962     136.676\n",
      "n_tokens_content                  0.6084      0.223      2.726      0.006       0.171       1.046\n",
      "n_unique_tokens                3925.7776   1917.809      2.047      0.041     166.822    7684.733\n",
      "n_non_stop_words              -1580.0751    647.933     -2.439      0.015   -2850.041    -310.109\n",
      "n_non_stop_unique_tokens      -1692.0357   1629.140     -1.039      0.299   -4885.192    1501.120\n",
      "num_hrefs                        26.5663      6.689      3.972      0.000      13.456      39.677\n",
      "num_self_hrefs                  -56.7022     17.771     -3.191      0.001     -91.534     -21.871\n",
      "num_imgs                          8.4753      9.224      0.919      0.358      -9.604      26.554\n",
      "num_videos                        4.7970     15.782      0.304      0.761     -26.137      35.731\n",
      "average_token_length           -572.6693    242.612     -2.360      0.018   -1048.195     -97.144\n",
      "num_keywords                     47.4215     37.459      1.266      0.206     -26.000     120.843\n",
      "data_channel_is_lifestyle     -1089.1043    399.872     -2.724      0.006   -1872.863    -305.346\n",
      "data_channel_is_entertainment -1201.8429    263.751     -4.557      0.000   -1718.801    -684.885\n",
      "data_channel_is_bus            -815.0865    388.262     -2.099      0.036   -1576.091     -54.082\n",
      "data_channel_is_socmed         -626.9611    376.842     -1.664      0.096   -1365.581     111.659\n",
      "data_channel_is_tech           -578.2568    376.982     -1.534      0.125   -1317.151     160.637\n",
      "data_channel_is_world          -555.6864    384.465     -1.445      0.148   -1309.248     197.875\n",
      "kw_min_min                        2.2540      1.624      1.388      0.165      -0.929       5.437\n",
      "kw_max_min                        0.0890      0.050      1.764      0.078      -0.010       0.188\n",
      "kw_avg_min                       -0.3684      0.309     -1.193      0.233      -0.974       0.237\n",
      "kw_min_max                       -0.0020      0.001     -1.640      0.101      -0.004       0.000\n",
      "kw_max_max                       -0.0005      0.001     -0.841      0.400      -0.002       0.001\n",
      "kw_avg_max                       -0.0008      0.001     -0.892      0.372      -0.002       0.001\n",
      "kw_min_avg                       -0.3846      0.077     -4.998      0.000      -0.535      -0.234\n",
      "kw_max_avg                       -0.2042      0.026     -7.962      0.000      -0.254      -0.154\n",
      "kw_avg_avg                        1.6732      0.146     11.495      0.000       1.388       1.959\n",
      "self_reference_min_shares         0.0261      0.007      3.482      0.000       0.011       0.041\n",
      "self_reference_max_shares         0.0057      0.004      1.410      0.159      -0.002       0.014\n",
      "self_reference_avg_sharess       -0.0057      0.010     -0.548      0.584      -0.026       0.015\n",
      "weekday_is_monday               280.1408    766.221      0.366      0.715   -1221.672    1781.954\n",
      "weekday_is_tuesday             -248.0148    764.860     -0.324      0.746   -1747.160    1251.130\n",
      "weekday_is_wednesday            -46.9285    766.483     -0.061      0.951   -1549.255    1455.398\n",
      "weekday_is_thursday            -246.8627    766.679     -0.322      0.747   -1749.573    1255.848\n",
      "weekday_is_friday              -229.8940    768.082     -0.299      0.765   -1735.355    1275.567\n",
      "weekday_is_saturday             277.3532    305.881      0.907      0.365    -322.182     876.889\n",
      "weekday_is_sunday              -136.0934    303.376     -0.449      0.654    -730.719     458.532\n",
      "is_weekend                      141.2598    515.499      0.274      0.784    -869.132    1151.652\n",
      "LDA_00                          496.5163    925.699      0.536      0.592   -1317.878    2310.910\n",
      "LDA_01                         -276.0052    907.569     -0.304      0.761   -2054.864    1502.854\n",
      "LDA_02                         -737.1081    920.824     -0.800      0.423   -2541.946    1067.730\n",
      "LDA_03                           95.7067    893.037      0.107      0.915   -1654.668    1846.081\n",
      "LDA_04                           71.7722    909.965      0.079      0.937   -1711.783    1855.327\n",
      "global_subjectivity            2439.4702    849.154      2.873      0.004     775.106    4103.835\n",
      "global_sentiment_polarity       735.0445   1662.263      0.442      0.658   -2523.034    3993.123\n",
      "global_rate_positive_words    -1.391e+04   7144.225     -1.947      0.052   -2.79e+04      94.678\n",
      "global_rate_negative_words     1317.4360   1.36e+04      0.097      0.923   -2.54e+04     2.8e+04\n",
      "rate_positive_words            2124.2312   5756.863      0.369      0.712   -9159.368    1.34e+04\n",
      "rate_negative_words            2057.9710   5802.502      0.355      0.723   -9315.082    1.34e+04\n",
      "avg_positive_polarity         -1632.2599   1362.217     -1.198      0.231   -4302.241    1037.721\n",
      "min_positive_polarity         -1981.2363   1140.547     -1.737      0.082   -4216.739     254.266\n",
      "max_positive_polarity           346.2898    429.653      0.806      0.420    -495.841    1188.420\n",
      "avg_negative_polarity         -1669.8502   1254.786     -1.331      0.183   -4129.262     789.562\n",
      "min_negative_polarity           115.2207    457.415      0.252      0.801    -781.324    1011.765\n",
      "max_negative_polarity          -210.5268   1043.191     -0.202      0.840   -2255.209    1834.155\n",
      "title_subjectivity             -100.0363    277.978     -0.360      0.719    -644.879     444.807\n",
      "title_sentiment_polarity        139.8942    254.996      0.549      0.583    -359.904     639.692\n",
      "abs_title_subjectivity          509.4033    369.585      1.378      0.168    -214.993    1233.800\n",
      "abs_title_sentiment_polarity    682.6629    401.875      1.699      0.089    -105.023    1470.349\n",
      "==============================================================================\n",
      "Omnibus:                   106659.721   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       6172873195.191\n",
      "Skew:                          35.491   Prob(JB):                         0.00\n",
      "Kurtosis:                    1964.298   Cond. No.                     1.04e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.41e-16. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "print(lm_a.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     1555.805495\n",
       "13479    8892.236930\n",
       "17500    2659.156704\n",
       "1445     2484.121981\n",
       "14432    2249.442951\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = lm_a.predict(df_train)\n",
    "predictions_train_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26924.000000\n",
       "mean      3353.851535\n",
       "std       1765.466251\n",
       "min      -1749.240619\n",
       "25%       2203.677273\n",
       "50%       3007.151713\n",
       "75%       4105.520204\n",
       "max      29899.105904\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3353.8515354308806"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction of the trained sample\n",
    "predictions_train_sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up the threshold value to mean and then evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16107\n",
       "1    10817\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = predictions_train_sample.apply(lambda res: 1 if res > predictions_train_sample.mean()  else 0)\n",
    "predictions_train_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321.0465012628138"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    21480\n",
       "1     5444\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= df_train['shares'].mean(), 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_sample\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6464492645966424\n",
      "Confusion matrix: \n",
      " [[14034  7446]\n",
      " [ 2073  3371]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.65      0.75     21480\n",
      "          1       0.31      0.62      0.41      5444\n",
      "\n",
      "avg / total       0.76      0.65      0.68     26924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the predictions can be observed as 0.64 when trained the model with all the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on train data by setting third quartile value as the threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     1555.805495\n",
       "13479    8892.236930\n",
       "17500    2659.156704\n",
       "1445     2484.121981\n",
       "14432    2249.442951\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s1 = lm_a.predict(df_train)\n",
    "predictions_train_s1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4105.52020362979"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_train_s1.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20193\n",
       "1     6731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s1 = predictions_train_s1.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_train_s1.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    22663\n",
       "1     4261\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= q3, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_s1\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7352547912642995\n",
      "Confusion matrix: \n",
      " [[17864  4799]\n",
      " [ 2329  1932]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83     22663\n",
      "          1       0.29      0.45      0.35      4261\n",
      "\n",
      "avg / total       0.79      0.74      0.76     26924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with threshold values for our classification of the target feature. Rather than dividing into below and above average popularity,divided it into viral and non-viral categories. For this threshold is set to classify the top 25th percentile as ‘popular’, and the rest as not popular. This did improve the performance of the model somewhat, giving an accuracy of .73."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11894, 61)"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37405    3606.530868\n",
       "6314     2661.771314\n",
       "12711    2815.793269\n",
       "4219     5407.401647\n",
       "7592     5282.194757\n",
       "dtype: float64"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = lm_a.predict(df_test)\n",
    "predictions_test_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_test_s1= lm_a.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11894.000000\n",
       "mean      3422.319726\n",
       "std       1787.204740\n",
       "min      -1703.951955\n",
       "25%       2236.142461\n",
       "50%       3065.446139\n",
       "75%       4218.904002\n",
       "max      30214.594129\n",
       "dtype: float64"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7118\n",
       "1    4776\n",
       "dtype: int64"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = predictions_test_sample.apply(lambda res: 1 if res > predictions_test_sample.mean() else 0)\n",
    "predictions_test_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjal\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9499\n",
       "1    2395\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >=df_test['shares'].mean(), 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 37405    1\n",
      "6314     0\n",
      "12711    0\n",
      "4219     1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 37405    0\n",
      "6314     0\n",
      "12711    0\n",
      "4219     0\n",
      "Name: shares_binary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_sample\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6442744240793677\n",
      "Confusion matrix: \n",
      " [[6193 3306]\n",
      " [ 925 1470]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.65      0.75      9499\n",
      "          1       0.31      0.61      0.41      2395\n",
      "\n",
      "avg / total       0.76      0.64      0.68     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for test data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data by setting third quartile value as the threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4218.904001881543"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_test_s1.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8920\n",
       "1    2974\n",
       "dtype: int64"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s1 = predictions_test_s1.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_test_s1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjal\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9992\n",
       "1    1902\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >= q3, 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 37405    0\n",
      "6314     0\n",
      "12711    0\n",
      "4219     1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 37405    0\n",
      "6314     0\n",
      "12711    0\n",
      "4219     0\n",
      "Name: shares_binary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_s1\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7354968891878257\n",
      "Confusion matrix: \n",
      " [[7883 2109]\n",
      " [1037  865]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83      9992\n",
      "          1       0.29      0.45      0.35      1902\n",
      "\n",
      "avg / total       0.79      0.74      0.76     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same experiment with this selection of features. When the threshold is set to 3rd quartile it is observed that performance of the model has improved to 0.73."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.Manually selected features\n",
    "\n",
    "### Training manually selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                      716.018466\n",
      "kw_avg_avg                       0.668974\n",
      "LDA_03                        1371.843778\n",
      "LDA_02                       -1184.159483\n",
      "self_reference_avg_sharess       0.020063\n",
      "data_channel_is_world          111.187295\n",
      "num_hrefs                       33.021886\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Import statsmodels package for training a linear regression model.\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# The formula specifies the target feature and the descriptive features used for training the \n",
    "# linear regression model.\n",
    "# We first train a simple linear regression with only one descriptive feature (Size).\n",
    "# For training the model we call the method fit() on the given data stored in our df dataframe.\n",
    "lm_m = sm.ols(formula=\"shares ~  kw_avg_avg + LDA_03 + LDA_02 + self_reference_avg_sharess + data_channel_is_world + num_hrefs\", data=df).fit()\n",
    "# Print the model weights/parameters\n",
    "print(lm_m.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the r-squared and p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 shares   R-squared:                       0.017\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     108.2\n",
      "Date:                Mon, 30 Apr 2018   Prob (F-statistic):          7.33e-136\n",
      "Time:                        11:51:56   Log-Likelihood:            -4.1417e+05\n",
      "No. Observations:               38463   AIC:                         8.284e+05\n",
      "Df Residuals:                   38456   BIC:                         8.284e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                    716.0185    177.552      4.033      0.000     368.012    1064.025\n",
      "kw_avg_avg                     0.6690      0.051     13.103      0.000       0.569       0.769\n",
      "LDA_03                      1371.8438    231.247      5.932      0.000     918.594    1825.093\n",
      "LDA_02                     -1184.1595    386.491     -3.064      0.002   -1941.691    -426.628\n",
      "self_reference_avg_sharess     0.0201      0.002      8.268      0.000       0.015       0.025\n",
      "data_channel_is_world        111.1873    261.152      0.426      0.670    -400.676     623.051\n",
      "num_hrefs                     33.0219      5.270      6.266      0.000      22.693      43.351\n",
      "==============================================================================\n",
      "Omnibus:                   106508.030   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       6091797016.498\n",
      "Skew:                          35.359   Prob(JB):                         0.00\n",
      "Kurtosis:                    1951.368   Cond. No.                     1.96e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.96e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(lm_m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     1584.176848\n",
       "13479    7301.296250\n",
       "17500    2525.570161\n",
       "1445     2421.594910\n",
       "14432    2349.973837\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = lm_m.predict(df_train)\n",
    "predictions_train_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26924.000000\n",
       "mean      3355.465885\n",
       "std       1493.933012\n",
       "min        149.831871\n",
       "25%       2424.756914\n",
       "50%       3026.907683\n",
       "75%       3976.855784\n",
       "max      30797.141136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3355.4658848367685"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16399\n",
       "1    10525\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = predictions_train_sample.apply(lambda res: 1 if res > predictions_train_sample.mean()  else 0)\n",
    "predictions_train_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321.0465012628138"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    21480\n",
       "1     5444\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= df_train['shares'].mean(), 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_sample\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6379809835091368\n",
      "Confusion matrix: \n",
      " [[14066  7414]\n",
      " [ 2333  3111]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.65      0.74     21480\n",
      "          1       0.30      0.57      0.39      5444\n",
      "\n",
      "avg / total       0.74      0.64      0.67     26924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on train data by setting third quartile value as the threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     1584.176848\n",
       "13479    7301.296250\n",
       "17500    2525.570161\n",
       "1445     2421.594910\n",
       "14432    2349.973837\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s2 = lm_m.predict(df_train)\n",
    "predictions_train_s2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3976.85578375863"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_train_s2.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20193\n",
       "1     6731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s2 = predictions_train_s2.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_train_s2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    22438\n",
       "1     4486\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= q3, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_s2\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7233323428911008\n",
      "Confusion matrix: \n",
      " [[17591  4847]\n",
      " [ 2602  1884]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.78      0.83     22438\n",
      "          1       0.28      0.42      0.34      4486\n",
      "\n",
      "avg / total       0.77      0.72      0.74     26924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11539, 60)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     1584.176848\n",
       "13479    7301.296250\n",
       "17500    2525.570161\n",
       "1445     2421.594910\n",
       "14432    2349.973837\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = lm_m.predict(df_test)\n",
    "predictions_test_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11539.000000\n",
       "mean      3361.998636\n",
       "std       1552.764773\n",
       "min        149.831871\n",
       "25%       2418.996829\n",
       "50%       3026.777831\n",
       "75%       3977.022113\n",
       "max      30797.141136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7066\n",
       "1    4473\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = predictions_test_sample.apply(lambda res: 1 if res > predictions_test_sample.mean() else 0)\n",
    "predictions_test_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9215\n",
       "1    2324\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >=df_test['shares'].mean(), 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_sample\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6383568766790884\n",
      "Confusion matrix: \n",
      " [[6054 3161]\n",
      " [1012 1312]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.66      0.74      9215\n",
      "          1       0.29      0.56      0.39      2324\n",
      "\n",
      "avg / total       0.74      0.64      0.67     11539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for test data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data by setting third quartile value as the threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     1584.176848\n",
       "13479    7301.296250\n",
       "17500    2525.570161\n",
       "1445     2421.594910\n",
       "14432    2349.973837\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s2 = lm_m.predict(df_test)\n",
    "predictions_test_s2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3977.0221131019507"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_test_s2.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8654\n",
       "1    2885\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s2 = predictions_test_s2.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_test_s2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9608\n",
       "1    1931\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test['shares_binary'] = np.where(df_test['shares'] >= q3, 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_s2\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7237195597538781\n",
      "Confusion matrix: \n",
      " [[7537 2071]\n",
      " [1117  814]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.78      0.83      9608\n",
      "          1       0.28      0.42      0.34      1931\n",
      "\n",
      "avg / total       0.77      0.72      0.74     11539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is observed as 0.63 when the threshold is set to mean, where there is improvement in the performance again when the threshold is set to 75%, which is 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Selection of features based on the random forest feature importance table.\n",
    "\n",
    "Training the model by considering the features from random forest importance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 shares   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                  0.019\n",
      "Method:                 Least Squares   F-statistic:                     29.75\n",
      "Date:                Mon, 30 Apr 2018   Prob (F-statistic):          1.55e-106\n",
      "Time:                        14:12:13   Log-Likelihood:            -2.9687e+05\n",
      "No. Observations:               27751   AIC:                         5.938e+05\n",
      "Df Residuals:                   27731   BIC:                         5.940e+05\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                   3.714e+10    2.4e+10      1.549      0.121   -9.86e+09    8.41e+10\n",
      "LDA_00                      7.427e+09    4.8e+09      1.549      0.121   -1.97e+09    1.68e+10\n",
      "LDA_01                      7.427e+09    4.8e+09      1.549      0.121   -1.97e+09    1.68e+10\n",
      "LDA_02                      7.427e+09    4.8e+09      1.549      0.121   -1.97e+09    1.68e+10\n",
      "LDA_03                      7.427e+09    4.8e+09      1.549      0.121   -1.97e+09    1.68e+10\n",
      "LDA_04                      7.427e+09    4.8e+09      1.549      0.121   -1.97e+09    1.68e+10\n",
      "average_token_length        -379.4982    263.489     -1.440      0.150    -895.951     136.954\n",
      "avg_negative_polarity      -2609.3605    661.560     -3.944      0.000   -3906.051   -1312.670\n",
      "avg_positive_polarity      -2173.8286    970.117     -2.241      0.025   -4075.305    -272.352\n",
      "global_rate_positive_words -1.968e+04   5268.293     -3.735      0.000      -3e+04   -9348.972\n",
      "global_sentiment_polarity   2025.6604   1070.081      1.893      0.058     -71.751    4123.072\n",
      "global_subjectivity         3807.8138    890.582      4.276      0.000    2062.229    5553.399\n",
      "kw_avg_avg                     1.2853      0.120     10.751      0.000       1.051       1.520\n",
      "kw_avg_max                    -0.0014      0.001     -2.176      0.030      -0.003      -0.000\n",
      "kw_avg_min                     0.8066      0.412      1.957      0.050      -0.001       1.615\n",
      "kw_max_avg                    -0.1027      0.025     -4.142      0.000      -0.151      -0.054\n",
      "kw_max_min                    -0.0975      0.068     -1.438      0.150      -0.230       0.035\n",
      "n_non_stop_unique_tokens   -3097.4089   1681.126     -1.842      0.065   -6392.498     197.681\n",
      "n_non_stop_words           -4.456e+10   2.88e+10     -1.549      0.121   -1.01e+11    1.18e+10\n",
      "n_tokens_content               0.7024      0.218      3.229      0.001       0.276       1.129\n",
      "n_unique_tokens             3659.2901   2376.215      1.540      0.124    -998.209    8316.789\n",
      "==============================================================================\n",
      "Omnibus:                    73698.498   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       2963558988.417\n",
      "Skew:                          31.693   Prob(JB):                         0.00\n",
      "Kurtosis:                    1602.677   Cond. No.                     9.47e+17\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.56e-21. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#Train a model with all the features selected using random forest feature importance table\n",
    "lm2= sm.ols(formula=\"shares ~  LDA_00 + LDA_01 + LDA_02 + LDA_03 + LDA_04 + average_token_length + avg_negative_polarity + avg_positive_polarity +  global_rate_positive_words + global_sentiment_polarity + global_subjectivity + kw_avg_avg + kw_avg_max + kw_avg_min + kw_max_avg + kw_max_min  + n_non_stop_unique_tokens + n_non_stop_words + n_tokens_content + n_unique_tokens \", data=df_train).fit()\n",
    "print(lm2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on training data\n",
    "Split the dataset into a training set and a test set. Fit the model on the training set, evaluate both on the training and the test set. Compare the prediction error on both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5794     2659.996544\n",
       "21138    5064.118523\n",
       "25763    2843.397133\n",
       "11341    4300.787422\n",
       "1651     2544.580452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = lm2.predict(df_train)\n",
    "predictions_train_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27751.000000\n",
       "mean      3325.328570\n",
       "std       1528.823779\n",
       "min      -1077.573326\n",
       "25%       2281.135578\n",
       "50%       3075.360252\n",
       "75%       4086.065605\n",
       "max      29173.156586\n",
       "dtype: float64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15909\n",
       "1    11842\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = predictions_train_sample.apply(lambda res: 1 if res > predictions_train_sample.mean()  else 0)\n",
    "predictions_train_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    22194\n",
       "1     5557\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >=df_train['shares'].mean(), 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 5794     0\n",
      "21138    1\n",
      "25763    0\n",
      "11341    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 5794     0\n",
      "21138    0\n",
      "25763    1\n",
      "11341    1\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_sample\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6233288890490433\n",
      "Confusion matrix: \n",
      " [[13825  8369]\n",
      " [ 2084  3473]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.62      0.73     22194\n",
      "          1       0.29      0.62      0.40      5557\n",
      "\n",
      "avg / total       0.75      0.62      0.66     27751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for train data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on train data by setting third quartile value as the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5794     2659.996544\n",
       "21138    5064.118523\n",
       "25763    2843.397133\n",
       "11341    4300.787422\n",
       "1651     2544.580452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s4 = lm2.predict(df_train)\n",
    "predictions_train_s4.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4086.065605163574"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_train_s4.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20813\n",
       "1     6938\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s4 = predictions_train_s4.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_train_s4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    23308\n",
       "1     4443\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= q3, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 5794     0\n",
      "21138    1\n",
      "25763    0\n",
      "11341    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 5794     0\n",
      "21138    0\n",
      "25763    1\n",
      "11341    1\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_s4\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7289106698857699\n",
      "Confusion matrix: \n",
      " [[18299  5009]\n",
      " [ 2514  1929]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83     23308\n",
      "          1       0.28      0.43      0.34      4443\n",
      "\n",
      "avg / total       0.78      0.73      0.75     27751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data\n",
    "Split the dataset into a training set and a test set. Fit the model on the training set, evaluate both on the training and the test set. Compare the prediction error on both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5794     2659.996544\n",
       "21138    5064.118523\n",
       "25763    2843.397133\n",
       "11341    4300.787422\n",
       "1651     2544.580452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = lm2.predict(df_test)\n",
    "predictions_test_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11893.000000\n",
       "mean      3337.153762\n",
       "std       1525.725429\n",
       "min       -908.052917\n",
       "25%       2290.293106\n",
       "50%       3087.251472\n",
       "75%       4116.549683\n",
       "max      23490.888374\n",
       "dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6821\n",
       "1    5072\n",
       "dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = predictions_test_sample.apply(lambda res: 1 if res > predictions_test_sample.mean()  else 0)\n",
    "predictions_test_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9407\n",
       "1    2486\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >=df_test['shares'].mean(), 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 5794     0\n",
      "21138    1\n",
      "25763    0\n",
      "11341    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 5794     0\n",
      "21138    0\n",
      "25763    1\n",
      "11341    1\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_sample\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6246531573194316\n",
      "Confusion matrix: \n",
      " [[5882 3525]\n",
      " [ 939 1547]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.63      0.72      9407\n",
      "          1       0.31      0.62      0.41      2486\n",
      "\n",
      "avg / total       0.75      0.62      0.66     11893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for test data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data by setting third quartile value as the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5794     2659.996544\n",
       "21138    5064.118523\n",
       "25763    2843.397133\n",
       "11341    4300.787422\n",
       "1651     2544.580452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s4 = lm2.predict(df_test)\n",
    "predictions_test_s4.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4116.5496826171875"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_test_s4.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8920\n",
       "1    2973\n",
       "dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s4 = predictions_test_s4.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_test_s4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    10013\n",
       "1     1880\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >= q3, 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 5794     0\n",
      "21138    1\n",
      "25763    0\n",
      "11341    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 5794     0\n",
      "21138    0\n",
      "25763    1\n",
      "11341    1\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_s4\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7283275876566048\n",
      "Confusion matrix: \n",
      " [[7851 2162]\n",
      " [1069  811]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.78      0.83     10013\n",
      "          1       0.27      0.43      0.33      1880\n",
      "\n",
      "avg / total       0.78      0.73      0.75     11893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Selection of features using  information gain entropy\n",
    "\n",
    "Selected the features using the information gain algorithm and evaluated the model on different aspects\n",
    "\n",
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#this will output a dictionary of each attribute, i.e. item in the vocabulary as keys and their information gain as values\n",
    "import sklearn\n",
    "res = dict(zip(col,\n",
    "               sklearn.feature_selection.mutual_info_classif(df3, y, discrete_features=True)\n",
    "               ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated the Information Gain for each attribute with respect to a class in a (sparse) document-term matrix. The Information Gain is defined as H(Class) - H(Class | Attribute), where H is the entropy.\n",
    "{'LDA_00': 5.3683915362330374,\n",
    " 'LDA_01': 5.3523199569360722,\n",
    " 'LDA_02': 5.3781644224537075,\n",
    " 'LDA_03': 5.3462810765221249,\n",
    " 'LDA_04': 5.3710643647200067,\n",
    " 'abs_title_sentiment_polarity': 0.50702816220588831,\n",
    " 'abs_title_subjectivity': 0.43979556291202926,\n",
    " 'average_token_length': 4.862218222274274,\n",
    " 'avg_negative_polarity': 3.2184776499478405,\n",
    " 'avg_positive_polarity': 4.550486467232763,\n",
    " 'data_channel_is_bus': 0.019734703530144952,\n",
    " 'data_channel_is_entertainment': 0.028221257938357381,\n",
    " 'data_channel_is_lifestyle': 0.016517076680820295,\n",
    " 'data_channel_is_socmed': 0.021559352173343017,\n",
    " 'data_channel_is_tech': 0.025760582972089992,\n",
    " 'data_channel_is_world': 0.033772286388906787,\n",
    " 'global_rate_negative_words': 3.2334070871857832,\n",
    " 'global_rate_positive_words': 3.6223875279391913,\n",
    " 'global_sentiment_polarity': 5.0554207505644913,\n",
    " 'global_subjectivity': 5.0455606551707159,\n",
    " 'is_weekend': 0.033357583699486673,\n",
    " 'kw_avg_avg': 5.3674749949656313,\n",
    " 'kw_avg_max': 5.0014755022737392,\n",
    " 'kw_avg_min': 4.1477465186447944,\n",
    " 'kw_max_avg': 4.2258022861775739,\n",
    " 'kw_max_max': 0.099661120751210974,\n",
    " 'kw_max_min': 1.6862121516285513,\n",
    " 'kw_min_avg': 2.7190278778614578,\n",
    " 'kw_min_max': 0.99983234514130503,\n",
    " 'kw_min_min': 0.053593571044521754,\n",
    " 'max_negative_polarity': 0.25845928194887174,\n",
    " 'max_positive_polarity': 0.17879915239025657,\n",
    " 'min_negative_polarity': 0.28497092261873314,\n",
    " 'min_positive_polarity': 0.18594115670637662,\n",
    " 'n_non_stop_unique_tokens': 4.5355325459776816,\n",
    " 'n_non_stop_words': 1.8600226943587341,\n",
    " 'n_tokens_content': 2.2139975492463311,\n",
    " 'n_tokens_title': 0.16149333202589627,\n",
    " 'n_unique_tokens': 4.7738715496223669,\n",
    " 'num_hrefs': 0.42329342722289792,\n",
    " 'num_imgs': 0.28439453282237359,\n",
    " 'num_keywords': 0.12456877659897686,\n",
    " 'num_self_hrefs': 0.19677041286643404,\n",
    " 'num_videos': 0.14253212459190581,\n",
    " 'rate_negative_words': 1.5064827587538716,\n",
    " 'rate_positive_words': 1.5158634846150842,\n",
    " 'self_reference_avg_sharess': 2.2845925840343497,\n",
    " 'self_reference_max_shares': 1.2087976581423132,\n",
    " 'self_reference_min_shares': 1.3049492964946465,\n",
    " 'timedelta': 1.7723839453974395,\n",
    " 'title_sentiment_polarity': 0.6089786677705652,\n",
    " 'title_subjectivity': 0.5472633834302385,\n",
    " 'weekday_is_friday': 0.018957945216486138,\n",
    " 'weekday_is_monday': 0.019821589042664917,\n",
    " 'weekday_is_saturday': 0.022387405911094269,\n",
    " 'weekday_is_sunday': 0.020253328014658761,\n",
    " 'weekday_is_thursday': 0.01962792154740356,\n",
    " 'weekday_is_tuesday': 0.020586316422148067,\n",
    " 'weekday_is_wednesday': 0.020629877393717369}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 shares   R-squared:                       0.022\n",
      "Model:                            OLS   Adj. R-squared:                  0.021\n",
      "Method:                 Least Squares   F-statistic:                     18.81\n",
      "Date:                Mon, 30 Apr 2018   Prob (F-statistic):          4.99e-105\n",
      "Time:                        11:55:28   Log-Likelihood:            -2.8865e+05\n",
      "No. Observations:               26924   AIC:                         5.774e+05\n",
      "Df Residuals:                   26891   BIC:                         5.776e+05\n",
      "Df Model:                          32                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                     9.487e+09   2.55e+10      0.373      0.709   -4.04e+10    5.94e+10\n",
      "LDA_00                        1.915e+09   5.14e+09      0.373      0.709   -8.16e+09     1.2e+10\n",
      "LDA_01                        1.915e+09   5.14e+09      0.373      0.709   -8.16e+09     1.2e+10\n",
      "LDA_02                        1.915e+09   5.14e+09      0.373      0.709   -8.16e+09     1.2e+10\n",
      "LDA_03                        1.915e+09   5.14e+09      0.373      0.709   -8.16e+09     1.2e+10\n",
      "LDA_04                        1.915e+09   5.14e+09      0.373      0.709   -8.16e+09     1.2e+10\n",
      "abs_title_sentiment_polarity  1028.8823    459.511      2.239      0.025     128.216    1929.549\n",
      "abs_title_subjectivity         417.6165    417.921      0.999      0.318    -401.530    1236.763\n",
      "average_token_length          -378.5008    278.191     -1.361      0.174    -923.770     166.769\n",
      "avg_negative_polarity         -974.7715    712.266     -1.369      0.171   -2370.851     421.308\n",
      "avg_positive_polarity        -1415.1778   1202.374     -1.177      0.239   -3771.893     941.537\n",
      "global_rate_negative_words    2277.2046   1.51e+04      0.151      0.880   -2.73e+04    3.18e+04\n",
      "global_rate_positive_words   -6507.9196   7983.503     -0.815      0.415   -2.22e+04    9140.162\n",
      "global_sentiment_polarity      358.3453   1846.993      0.194      0.846   -3261.858    3978.549\n",
      "global_subjectivity           2325.3954    953.239      2.439      0.015     456.997    4193.794\n",
      "kw_avg_avg                       1.7961      0.152     11.803      0.000       1.498       2.094\n",
      "kw_avg_max                      -0.0004      0.001     -0.457      0.648      -0.002       0.001\n",
      "kw_avg_min                      -0.1921      0.349     -0.550      0.582      -0.877       0.492\n",
      "kw_max_avg                      -0.2175      0.029     -7.609      0.000      -0.274      -0.161\n",
      "kw_max_min                       0.0695      0.056      1.238      0.216      -0.041       0.179\n",
      "kw_min_avg                      -0.4370      0.083     -5.239      0.000      -0.600      -0.273\n",
      "kw_min_max                      -0.0025      0.001     -1.878      0.060      -0.005       0.000\n",
      "n_non_stop_unique_tokens      -497.5577   1796.132     -0.277      0.782   -4018.070    3022.955\n",
      "n_non_stop_words              -1.14e+10   3.06e+10     -0.373      0.709   -7.14e+10    4.86e+10\n",
      "n_tokens_content                 0.4941      0.242      2.040      0.041       0.019       0.969\n",
      "n_unique_tokens               1591.1773   2543.815      0.626      0.532   -3394.833    6577.188\n",
      "num_hrefs                       27.2812      7.197      3.791      0.000      13.175      41.387\n",
      "rate_negative_words           1458.7075   7826.861      0.186      0.852   -1.39e+04    1.68e+04\n",
      "rate_positive_words           1176.7755   7786.353      0.151      0.880   -1.41e+04    1.64e+04\n",
      "self_reference_avg_sharess       0.0238      0.013      1.862      0.063      -0.001       0.049\n",
      "self_reference_max_shares       -0.0052      0.005     -1.066      0.287      -0.015       0.004\n",
      "self_reference_min_shares       -0.0082      0.009     -0.884      0.376      -0.026       0.010\n",
      "timedelta                        1.5697      0.397      3.958      0.000       0.792       2.347\n",
      "title_sentiment_polarity       -66.3942    292.232     -0.227      0.820    -639.184     506.395\n",
      "title_subjectivity              55.6192    316.429      0.176      0.860    -564.597     675.836\n",
      "==============================================================================\n",
      "Omnibus:                    77480.018   Durbin-Watson:                   2.009\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       6561443726.461\n",
      "Skew:                          39.058   Prob(JB):                         0.00\n",
      "Kurtosis:                    2420.179   Cond. No.                     2.58e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.4e-16. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#Train a model with all the features\n",
    "lm1= sm.ols(formula=\"shares ~  LDA_00 + LDA_01 + LDA_02 + LDA_03 + LDA_04 + abs_title_sentiment_polarity + abs_title_subjectivity + average_token_length + avg_negative_polarity + avg_positive_polarity + global_rate_negative_words +  global_rate_positive_words + global_sentiment_polarity + global_subjectivity + kw_avg_avg + kw_avg_max + kw_avg_min + kw_max_avg + kw_max_min + kw_min_avg + kw_min_max + n_non_stop_unique_tokens + n_non_stop_words + n_tokens_content + n_unique_tokens + num_hrefs + rate_negative_words + rate_positive_words + self_reference_avg_sharess + self_reference_max_shares + self_reference_min_shares + timedelta + title_sentiment_polarity + title_subjectivity\", data=df_train).fit()\n",
    "print(lm1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on training  data\n",
    "Split the dataset into a training set and a test set. Fit the model on the training set, evaluate both on the training and the test set. Compare the prediction error on both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     2378.248789\n",
       "13479    8586.563070\n",
       "17500    2470.895708\n",
       "1445     2943.742937\n",
       "14432    2552.879938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = lm1.predict(df_train)\n",
    "predictions_train_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26924.000000\n",
       "mean      3320.966254\n",
       "std       1639.463732\n",
       "min      -2746.037458\n",
       "25%       2244.197678\n",
       "50%       3047.563269\n",
       "75%       4100.809010\n",
       "max      36898.778675\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3320.9662540495583"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15585\n",
       "1    11339\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_sample = predictions_train_sample.apply(lambda res: 1 if res > predictions_train_sample.mean()  else 0)\n",
    "predictions_train_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321.0465012628138"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    21480\n",
       "1     5444\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= df_train['shares'].mean(), 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_sample\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6327811617887387\n",
      "Confusion matrix: \n",
      " [[13589  7891]\n",
      " [ 1996  3448]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.63      0.73     21480\n",
      "          1       0.30      0.63      0.41      5444\n",
      "\n",
      "avg / total       0.76      0.63      0.67     26924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on train data by setting third quartile value as the threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     2378.248789\n",
       "13479    8586.563070\n",
       "17500    2470.895708\n",
       "1445     2943.742937\n",
       "14432    2552.879938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s3 = lm1.predict(df_train)\n",
    "predictions_train_s3.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4100.809010028839"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_train_s3.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20193\n",
       "1     6731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_s3 = predictions_train_s3.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_train_s3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    22663\n",
       "1     4261\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['shares_binary'] = np.where(df_train['shares'] >= q3, 1, 0)\n",
    "df_train['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_train_s3\n",
    "y1 = df_train.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7343633932550884\n",
      "Confusion matrix: \n",
      " [[17852  4811]\n",
      " [ 2341  1920]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83     22663\n",
      "          1       0.29      0.45      0.35      4261\n",
      "\n",
      "avg / total       0.79      0.73      0.76     26924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test  data\n",
    "Split the dataset into a training set and a test set. Fit the model on the training set, evaluate both on the training and the test set. Compare the prediction error on both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11539, 61)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     2378.248789\n",
       "13479    8586.563070\n",
       "17500    2470.895708\n",
       "1445     2943.742937\n",
       "14432    2552.879938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = lm1.predict(df_test)\n",
    "predictions_test_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11539.000000\n",
       "mean      3324.318794\n",
       "std       1678.672704\n",
       "min      -2746.037458\n",
       "25%       2230.327971\n",
       "50%       3054.235016\n",
       "75%       4106.119324\n",
       "max      36898.778675\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6694\n",
       "1    4845\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_sample = predictions_test_sample.apply(lambda res: 1 if res > predictions_test_sample.mean() else 0)\n",
    "predictions_test_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9215\n",
       "1    2324\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >=df_test['shares'].mean(), 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_sample\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6321171678654997\n",
      "Confusion matrix: \n",
      " [[5832 3383]\n",
      " [ 862 1462]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.63      0.73      9215\n",
      "          1       0.30      0.63      0.41      2324\n",
      "\n",
      "avg / total       0.76      0.63      0.67     11539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for test data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data by setting third quartile value as the threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8543     2378.248789\n",
       "13479    8586.563070\n",
       "17500    2470.895708\n",
       "1445     2943.742937\n",
       "14432    2552.879938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s3 = lm1.predict(df_test)\n",
    "predictions_test_s3.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4106.119323730469"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = predictions_test_s3.quantile(q=0.75,interpolation='linear')\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8654\n",
       "1    2885\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_s3 = predictions_test_s3.apply(lambda res: 1 if res > q3  else 0)\n",
    "predictions_test_s3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tejaswis/anaconda3/envs/comp47350py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9710\n",
       "1    1829\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['shares_binary'] = np.where(df_test['shares'] >= q3, 1, 0)\n",
    "df_test['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 8543     0\n",
      "13479    1\n",
      "17500    0\n",
      "1445     0\n",
      "Name: shares_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x1 = predictions_test_s3\n",
    "y1 = df_test.shares_binary\n",
    "print(\"Descriptive features:\\n\", x1.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7342923996880145\n",
      "Confusion matrix: \n",
      " [[7649 2061]\n",
      " [1005  824]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83      9710\n",
      "          1       0.29      0.45      0.35      1829\n",
      "\n",
      "avg / total       0.79      0.73      0.76     11539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Some more evaluation metrics for training data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y1, x1))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y1, x1))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y1, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22087</th>\n",
       "      <td>295.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.584775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.797251</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>230.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>172520.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6901.963303</td>\n",
       "      <td>3713.878246</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817682</td>\n",
       "      <td>0.121907</td>\n",
       "      <td>0.020021</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.480934</td>\n",
       "      <td>0.084975</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.365606</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.269444</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>545.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0.549367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652672</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.027228</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>71.285714</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>232285.714286</td>\n",
       "      <td>1368.444444</td>\n",
       "      <td>3303.462238</td>\n",
       "      <td>2227.736414</td>\n",
       "      <td>838.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885712</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.410718</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.153182</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "22087      295.0            10.0             291.0         0.584775   \n",
       "9849       545.0            13.0             404.0         0.549367   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "22087               1.0                  0.792683        9.0             4.0   \n",
       "9849                1.0                  0.652672       17.0             2.0   \n",
       "\n",
       "       num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "22087       2.0         0.0              4.797251          10.0   \n",
       "9849        1.0         0.0              5.027228           7.0   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "22087                        1.0                            0.0   \n",
       "9849                         0.0                            0.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "22087                  0.0                     0.0                   0.0   \n",
       "9849                   0.0                     0.0                   0.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "22087                    0.0        -1.0       474.0  230.111111         0.0   \n",
       "9849                     1.0         4.0       143.0   71.285714     13100.0   \n",
       "\n",
       "       kw_max_max     kw_avg_max   kw_min_avg   kw_max_avg   kw_avg_avg  \\\n",
       "22087    843300.0  172520.000000     0.000000  6901.963303  3713.878246   \n",
       "9849     843300.0  232285.714286  1368.444444  3303.462238  2227.736414   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "22087                     3000.0                     3000.0   \n",
       "9849                       838.0                      838.0   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "22087                      3000.0                0.0                 0.0   \n",
       "9849                        838.0                0.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "22087                   1.0                  0.0                0.0   \n",
       "9849                    0.0                  0.0                1.0   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "22087                  0.0                0.0         0.0  0.817682  0.121907   \n",
       "9849                   0.0                0.0         0.0  0.028572  0.028572   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "22087  0.020021  0.020070  0.020320             0.480934   \n",
       "9849   0.885712  0.028571  0.028574             0.410718   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "22087                   0.084975                    0.034364   \n",
       "9849                    0.030829                    0.014851   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "22087                    0.020619             0.625000             0.375000   \n",
       "9849                     0.007426             0.666667             0.333333   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "22087               0.365606               0.033333                   0.80   \n",
       "9849                0.153182               0.100000                   0.25   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "22087              -0.269444              -0.500000              -0.125000   \n",
       "9849               -0.444444              -0.666667              -0.166667   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "22087                 0.0                       0.0                     0.5   \n",
       "9849                  0.0                       0.0                     0.5   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "22087                           0.0     748  \n",
       "9849                            0.0     735  "
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffle.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 60)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cont=df_shuffle\n",
    "df_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22087</th>\n",
       "      <td>0.396957</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.034340</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.029605</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204577</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>0.085244</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882079</td>\n",
       "      <td>0.131657</td>\n",
       "      <td>0.021762</td>\n",
       "      <td>0.021661</td>\n",
       "      <td>0.021916</td>\n",
       "      <td>0.480934</td>\n",
       "      <td>0.426827</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.111493</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.365606</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.730556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>0.742739</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.055921</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625158</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.015534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275448</td>\n",
       "      <td>0.378923</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.051133</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>0.962731</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.410718</td>\n",
       "      <td>0.378551</td>\n",
       "      <td>0.095515</td>\n",
       "      <td>0.040154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.153182</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>0.254495</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.043427</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513638</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520693</td>\n",
       "      <td>0.554781</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.062804</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>0.043479</td>\n",
       "      <td>0.043172</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.450728</td>\n",
       "      <td>0.501715</td>\n",
       "      <td>0.297101</td>\n",
       "      <td>0.073470</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.303170</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.856270</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30837</th>\n",
       "      <td>0.192254</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.051806</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593162</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307618</td>\n",
       "      <td>0.856614</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.095456</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030825</td>\n",
       "      <td>0.806062</td>\n",
       "      <td>0.031058</td>\n",
       "      <td>0.031009</td>\n",
       "      <td>0.180923</td>\n",
       "      <td>0.480681</td>\n",
       "      <td>0.476106</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.147811</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.458460</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.664087</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.011027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22399</th>\n",
       "      <td>0.388658</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.566960</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455334</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068321</td>\n",
       "      <td>0.132665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576336</td>\n",
       "      <td>0.036005</td>\n",
       "      <td>0.036259</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.214210</td>\n",
       "      <td>0.509041</td>\n",
       "      <td>0.542350</td>\n",
       "      <td>0.354346</td>\n",
       "      <td>0.059586</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.352684</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.763393</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29327</th>\n",
       "      <td>0.225450</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.075879</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.029605</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255120</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.040428</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.221995</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.462397</td>\n",
       "      <td>0.519431</td>\n",
       "      <td>0.320068</td>\n",
       "      <td>0.075687</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.487362</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.677160</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35443</th>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.070215</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562207</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.031898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605987</td>\n",
       "      <td>0.605184</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218294</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>0.210001</td>\n",
       "      <td>0.030877</td>\n",
       "      <td>0.590141</td>\n",
       "      <td>0.465209</td>\n",
       "      <td>0.589357</td>\n",
       "      <td>0.453979</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.355916</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16627</th>\n",
       "      <td>0.554633</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.069271</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557582</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196121</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.060026</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024589</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.861302</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.465677</td>\n",
       "      <td>0.262952</td>\n",
       "      <td>0.055272</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.347948</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.786574</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16655</th>\n",
       "      <td>0.553250</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.077767</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552896</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200418</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>0.051958</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026970</td>\n",
       "      <td>0.027394</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.970896</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.484821</td>\n",
       "      <td>0.508935</td>\n",
       "      <td>0.263501</td>\n",
       "      <td>0.106671</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.397551</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.820253</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.543579</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818688</td>\n",
       "      <td>0.399225</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.062370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.935326</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.657792</td>\n",
       "      <td>0.647055</td>\n",
       "      <td>0.243613</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.115260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "22087   0.396957        0.380952          0.034340         0.000834   \n",
       "9849    0.742739        0.523810          0.047675         0.000784   \n",
       "28004   0.254495        0.285714          0.043427         0.000618   \n",
       "30837   0.192254        0.571429          0.051806         0.000820   \n",
       "22399   0.388658        0.523810          0.042837         0.000850   \n",
       "29327   0.225450        0.714286          0.075879         0.000650   \n",
       "35443   0.091286        0.428571          0.070215         0.000688   \n",
       "16627   0.554633        0.428571          0.069271         0.000711   \n",
       "16655   0.553250        0.476190          0.077767         0.000698   \n",
       "7224    0.813278        0.380952          0.015577         0.001031   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "22087           0.00096                  0.001220   0.029605        0.034483   \n",
       "9849            0.00096                  0.001004   0.055921        0.017241   \n",
       "28004           0.00096                  0.000816   0.016447        0.043103   \n",
       "30837           0.00096                  0.001227   0.013158        0.017241   \n",
       "22399           0.00096                  0.001157   0.003289        0.000000   \n",
       "29327           0.00096                  0.000879   0.029605        0.017241   \n",
       "35443           0.00096                  0.000956   0.049342        0.034483   \n",
       "16627           0.00096                  0.001059   0.016447        0.008621   \n",
       "16655           0.00096                  0.001037   0.075658        0.077586   \n",
       "7224            0.00096                  0.001252   0.019737        0.000000   \n",
       "\n",
       "       num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "22087  0.015625    0.000000              0.596559      1.000000   \n",
       "9849   0.007812    0.000000              0.625158      0.666667   \n",
       "28004  0.015625    0.000000              0.513638      0.444444   \n",
       "30837  0.007812    0.000000              0.593162      0.666667   \n",
       "22399  0.000000    0.010989              0.566960      0.555556   \n",
       "29327  0.015625    0.000000              0.541125      0.666667   \n",
       "35443  0.046875    0.000000              0.562207      0.666667   \n",
       "16627  0.007812    0.000000              0.557582      0.888889   \n",
       "16655  0.109375    0.000000              0.552896      0.777778   \n",
       "7224   0.000000    0.010989              0.543579      0.555556   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "22087                        1.0                            0.0   \n",
       "9849                         0.0                            0.0   \n",
       "28004                        0.0                            0.0   \n",
       "30837                        0.0                            1.0   \n",
       "22399                        0.0                            0.0   \n",
       "29327                        0.0                            1.0   \n",
       "35443                        0.0                            0.0   \n",
       "16627                        1.0                            0.0   \n",
       "16655                        0.0                            1.0   \n",
       "7224                         0.0                            0.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "22087                  0.0                     0.0                   0.0   \n",
       "9849                   0.0                     0.0                   0.0   \n",
       "28004                  0.0                     0.0                   1.0   \n",
       "30837                  0.0                     0.0                   0.0   \n",
       "22399                  1.0                     0.0                   0.0   \n",
       "29327                  0.0                     0.0                   0.0   \n",
       "35443                  0.0                     0.0                   1.0   \n",
       "16627                  0.0                     0.0                   0.0   \n",
       "16655                  0.0                     0.0                   0.0   \n",
       "7224                   0.0                     0.0                   0.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "22087                    0.0    0.000000    0.001588    0.005396    0.000000   \n",
       "9849                     1.0    0.013228    0.000479    0.001688    0.015534   \n",
       "28004                    0.0    0.000000    0.002899    0.005366    0.008419   \n",
       "30837                    0.0    0.000000    0.003686    0.006404    0.016246   \n",
       "22399                    0.0    0.000000    0.005362    0.011605    0.000000   \n",
       "29327                    0.0    0.000000    0.002084    0.003189    0.000000   \n",
       "35443                    0.0    0.000000    0.001374    0.002515    0.031898   \n",
       "16627                    0.0    0.013228    0.002523    0.005931    0.000000   \n",
       "16655                    0.0    0.000000    0.002182    0.005987    0.000000   \n",
       "7224                     0.0    0.013228    0.001139    0.004039    0.000000   \n",
       "\n",
       "       kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  kw_avg_avg  \\\n",
       "22087    1.000000    0.204577    0.000277    0.023130    0.085244   \n",
       "9849     1.000000    0.275448    0.378923    0.011071    0.051133   \n",
       "28004    1.000000    0.520693    0.554781    0.011894    0.062804   \n",
       "30837    1.000000    0.307618    0.856614    0.017715    0.095456   \n",
       "22399    1.000000    0.455334    0.000277    0.068321    0.132665   \n",
       "29327    1.000000    0.255120    0.000277    0.011817    0.040428   \n",
       "35443    1.000000    0.605987    0.605184    0.014760    0.072793   \n",
       "16627    1.000000    0.196121    0.000277    0.014603    0.060026   \n",
       "16655    1.000000    0.200418    0.000277    0.012459    0.051958   \n",
       "7224     0.818688    0.399225    0.000277    0.016352    0.062370   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "22087                   0.003557                   0.003557   \n",
       "9849                    0.000994                   0.000994   \n",
       "28004                   0.001542                   0.016483   \n",
       "30837                   0.011502                   0.025969   \n",
       "22399                   0.000000                   0.000000   \n",
       "29327                   0.001897                   0.002016   \n",
       "35443                   0.001186                   0.003202   \n",
       "16627                   0.003320                   0.003320   \n",
       "16655                   0.001156                   0.002609   \n",
       "7224                    0.000000                   0.000000   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "22087                    0.003557                0.0                 0.0   \n",
       "9849                     0.000994                0.0                 0.0   \n",
       "28004                    0.009012                1.0                 0.0   \n",
       "30837                    0.018736                0.0                 0.0   \n",
       "22399                    0.000000                0.0                 1.0   \n",
       "29327                    0.001957                1.0                 0.0   \n",
       "35443                    0.002411                0.0                 0.0   \n",
       "16627                    0.003320                1.0                 0.0   \n",
       "16655                    0.001868                0.0                 1.0   \n",
       "7224                     0.000000                0.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "22087                   1.0                  0.0                0.0   \n",
       "9849                    0.0                  0.0                1.0   \n",
       "28004                   0.0                  0.0                0.0   \n",
       "30837                   0.0                  1.0                0.0   \n",
       "22399                   0.0                  0.0                0.0   \n",
       "29327                   0.0                  0.0                0.0   \n",
       "35443                   0.0                  0.0                0.0   \n",
       "16627                   0.0                  0.0                0.0   \n",
       "16655                   0.0                  0.0                0.0   \n",
       "7224                    1.0                  0.0                0.0   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "22087                  0.0                0.0         0.0  0.882079  0.131657   \n",
       "9849                   0.0                0.0         0.0  0.030822  0.030857   \n",
       "28004                  0.0                0.0         0.0  0.043151  0.043203   \n",
       "30837                  0.0                0.0         0.0  0.030825  0.806062   \n",
       "22399                  0.0                0.0         0.0  0.576336  0.036005   \n",
       "29327                  0.0                0.0         0.0  0.030827  0.765217   \n",
       "35443                  0.0                1.0         1.0  0.218294  0.030953   \n",
       "16627                  0.0                0.0         0.0  0.024589  0.024008   \n",
       "16655                  0.0                0.0         0.0  0.026970  0.027394   \n",
       "7224                   0.0                0.0         0.0  0.035959  0.036057   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "22087  0.021762  0.021661  0.021916             0.480934   \n",
       "9849   0.962731  0.030837  0.030817             0.410718   \n",
       "28004  0.043479  0.043172  0.905956             0.450728   \n",
       "30837  0.031058  0.031009  0.180923             0.480681   \n",
       "22399  0.036259  0.216321  0.214210             0.509041   \n",
       "29327  0.031102  0.221995  0.030817             0.462397   \n",
       "35443  0.210001  0.030877  0.590141             0.465209   \n",
       "16627  0.145774  0.024039  0.861302             0.474195   \n",
       "16655  0.027205  0.970896  0.027003             0.484821   \n",
       "7224   0.036232  0.935326  0.035951             0.657792   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "22087                   0.426827                    0.221009   \n",
       "9849                    0.378551                    0.095515   \n",
       "28004                   0.501715                    0.297101   \n",
       "30837                   0.476106                    0.351601   \n",
       "22399                   0.542350                    0.354346   \n",
       "29327                   0.519431                    0.320068   \n",
       "35443                   0.589357                    0.453979   \n",
       "16627                   0.465677                    0.262952   \n",
       "16655                   0.508935                    0.263501   \n",
       "7224                    0.647055                    0.243613   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "22087                    0.111493             0.625000             0.375000   \n",
       "9849                     0.040154             0.666667             0.333333   \n",
       "28004                    0.073470             0.772727             0.227273   \n",
       "30837                    0.147811             0.666667             0.333333   \n",
       "22399                    0.059586             0.833333             0.166667   \n",
       "29327                    0.075687             0.780488             0.219512   \n",
       "35443                    0.009088             0.976744             0.023256   \n",
       "16627                    0.055272             0.800000             0.200000   \n",
       "16655                    0.106671             0.675000             0.325000   \n",
       "7224                     0.040965             0.833333             0.166667   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "22087               0.365606               0.033333                   0.80   \n",
       "9849                0.153182               0.100000                   0.25   \n",
       "28004               0.303170               0.100000                   1.00   \n",
       "30837               0.458460               0.100000                   1.00   \n",
       "22399               0.352684               0.033333                   0.70   \n",
       "29327               0.487362               0.062500                   0.80   \n",
       "35443               0.355916               0.033333                   1.00   \n",
       "16627               0.347948               0.100000                   0.60   \n",
       "16655               0.397551               0.062500                   0.90   \n",
       "7224                0.502273               0.136364                   1.00   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "22087               0.730556               0.500000               0.875000   \n",
       "9849                0.555556               0.333333               0.833333   \n",
       "28004               0.856270               0.800000               0.928571   \n",
       "30837               0.664087               0.250000               0.900000   \n",
       "22399               0.763393               0.500000               0.928571   \n",
       "29327               0.677160               0.500000               0.844444   \n",
       "35443               0.833333               0.833333               0.833333   \n",
       "16627               0.786574               0.500000               0.875000   \n",
       "16655               0.820253               0.600000               0.950000   \n",
       "7224                0.812500               0.812500               0.812500   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "22087            0.000000                  0.500000                1.000000   \n",
       "9849             0.000000                  0.500000                1.000000   \n",
       "28004            0.300000                  0.500000                0.400000   \n",
       "30837            0.300000                  0.550000                0.400000   \n",
       "22399            0.454545                  0.568182                0.090909   \n",
       "29327            0.300000                  0.633333                0.400000   \n",
       "35443            0.500000                  0.750000                0.000000   \n",
       "16627            0.000000                  0.500000                1.000000   \n",
       "16655            0.800000                  0.700000                0.600000   \n",
       "7224             0.200000                  0.550000                0.600000   \n",
       "\n",
       "       abs_title_sentiment_polarity    shares  \n",
       "22087                      0.000000  0.000886  \n",
       "9849                       0.000000  0.000870  \n",
       "28004                      0.000000  0.002015  \n",
       "30837                      0.100000  0.011027  \n",
       "22399                      0.136364  0.004149  \n",
       "29327                      0.266667  0.001185  \n",
       "35443                      0.500000  0.003912  \n",
       "16627                      0.000000  0.004149  \n",
       "16655                      0.400000  0.000714  \n",
       "7224                       0.100000  0.115260  "
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Range normalise all columns\n",
    "df_norm = (df_cont - df_cont.min()) / (df_cont.max() - df_cont.min())\n",
    "df_norm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x184a13378d0>"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18493772278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm.plot(kind='scatter', x='global_rate_positive_words', y='shares', label=\"%.3f\" % df_norm[['global_rate_positive_words', 'shares']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='Floor', y='RentalPrice', label=\"%.3f\" % df[['Floor', 'RentalPrice']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='BroadbandRate', y='RentalPrice', label=\"%.3f\" % df[['BroadbandRate', 'RentalPrice']].corr().as_matrix()[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x184a127a940>"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18488aeab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm.plot(kind='scatter', x='LDA_02', y='shares', label=\"%.3f\" % df_norm[['global_rate_positive_words', 'shares']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='Floor', y='RentalPrice', label=\"%.3f\" % df[['Floor', 'RentalPrice']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='BroadbandRate', y='RentalPrice', label=\"%.3f\" % df[['BroadbandRate', 'RentalPrice']].corr().as_matrix()[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x184a0fb03c8>"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x184c08e6b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm.plot(kind='scatter', x='self_reference_max_shares', y='shares', label=\"%.3f\" % df_norm[['global_rate_positive_words', 'shares']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='Floor', y='RentalPrice', label=\"%.3f\" % df[['Floor', 'RentalPrice']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='BroadbandRate', y='RentalPrice', label=\"%.3f\" % df[['BroadbandRate', 'RentalPrice']].corr().as_matrix()[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18488ac3208>"
      ]
     },
     "execution_count": 1024,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18488afe400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm.plot(kind='scatter', x='LDA_01', y='shares', label=\"%.3f\" % df_norm[['global_rate_positive_words', 'shares']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='Floor', y='RentalPrice', label=\"%.3f\" % df[['Floor', 'RentalPrice']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='BroadbandRate', y='RentalPrice', label=\"%.3f\" % df[['BroadbandRate', 'RentalPrice']].corr().as_matrix()[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18495213a90>"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18488b0d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm.plot(kind='scatter', x='kw_max_min', y='shares', label=\"%.3f\" % df_norm[['global_rate_positive_words', 'shares']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='Floor', y='RentalPrice', label=\"%.3f\" % df[['Floor', 'RentalPrice']].corr().as_matrix()[0,1])\n",
    "#df.plot(kind='scatter', x='BroadbandRate', y='RentalPrice', label=\"%.3f\" % df[['BroadbandRate', 'RentalPrice']].corr().as_matrix()[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 60)"
      ]
     },
     "execution_count": 1026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27750, 60)"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_norm=df_norm.head(a)\n",
    "df_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11894, 60)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_norm=df_norm.head(b)\n",
    "df_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 shares   R-squared:                       0.018\n",
      "Model:                            OLS   Adj. R-squared:                  0.018\n",
      "Method:                 Least Squares   F-statistic:                     25.78\n",
      "Date:                Mon, 30 Apr 2018   Prob (F-statistic):           1.36e-95\n",
      "Time:                        00:41:59   Log-Likelihood:                 80490.\n",
      "No. Observations:               27750   AIC:                        -1.609e+05\n",
      "Df Residuals:                   27729   BIC:                        -1.608e+05\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                     -0.3451      1.934     -0.178      0.858      -4.137       3.446\n",
      "LDA_00                         0.3216      1.793      0.179      0.858      -3.193       3.836\n",
      "LDA_01                         0.3200      1.791      0.179      0.858      -3.190       3.830\n",
      "LDA_02                         0.3184      1.779      0.179      0.858      -3.170       3.806\n",
      "LDA_03                         0.3224      1.792      0.180      0.857      -3.190       3.835\n",
      "LDA_04                         0.3215      1.793      0.179      0.858      -3.193       3.837\n",
      "average_token_length          -0.0017      0.003     -0.654      0.513      -0.007       0.003\n",
      "avg_negative_polarity         -0.0020      0.001     -2.372      0.018      -0.004      -0.000\n",
      "avg_positive_polarity         -0.0028      0.001     -2.273      0.023      -0.005      -0.000\n",
      "global_rate_positive_words    -0.0026      0.001     -2.484      0.013      -0.005      -0.001\n",
      "global_sentiment_polarity      0.0033      0.002      2.175      0.030       0.000       0.006\n",
      "global_subjectivity            0.0036      0.001      3.192      0.001       0.001       0.006\n",
      "kw_avg_avg                     0.0730      0.006     11.475      0.000       0.061       0.085\n",
      "kw_avg_max                    -0.0026      0.001     -3.815      0.000      -0.004      -0.001\n",
      "kw_avg_min                    -0.0155      0.016     -0.964      0.335      -0.047       0.016\n",
      "kw_max_avg                    -0.0528      0.008     -6.292      0.000      -0.069      -0.036\n",
      "kw_max_min                     0.0220      0.019      1.177      0.239      -0.015       0.059\n",
      "n_non_stop_unique_tokens      -2.6401      1.296     -2.036      0.042      -5.181      -0.099\n",
      "n_non_stop_words              -1.0562      2.017     -0.524      0.600      -5.009       2.896\n",
      "n_tokens_content               0.0078      0.002      3.376      0.001       0.003       0.012\n",
      "n_unique_tokens                4.0455      1.656      2.443      0.015       0.800       7.291\n",
      "==============================================================================\n",
      "Omnibus:                    76873.309   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       4791467428.715\n",
      "Skew:                          35.302   Prob(JB):                         0.00\n",
      "Kurtosis:                    2037.450   Cond. No.                     1.03e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.03e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Train a model with all the normalised features\n",
    "lm_norm= sm.ols(formula=\"shares ~  LDA_00 + LDA_01 + LDA_02 + LDA_03 + LDA_04 + average_token_length + avg_negative_polarity + avg_positive_polarity +  global_rate_positive_words + global_sentiment_polarity + global_subjectivity + kw_avg_avg + kw_avg_max + kw_avg_min + kw_max_avg + kw_max_min  + n_non_stop_unique_tokens + n_non_stop_words + n_tokens_content + n_unique_tokens \", data=df_train_norm).fit()\n",
    "print(lm_norm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22087    0.004593\n",
       "9849     0.003266\n",
       "28004    0.003056\n",
       "30837    0.004340\n",
       "22399    0.005759\n",
       "dtype: float64"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_norm = lm_norm.predict(df_train_norm)\n",
    "predictions_train_norm.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27750.000000\n",
       "mean         0.004007\n",
       "std          0.001815\n",
       "min         -0.000883\n",
       "25%          0.002737\n",
       "50%          0.003672\n",
       "75%          0.004941\n",
       "max          0.032094\n",
       "dtype: float64"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16109\n",
       "1    11641\n",
       "dtype: int64"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_norm = predictions_train_norm.apply(lambda res: 1 if res > predictions_train_norm.mean()  else 0)\n",
    "predictions_train_norm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjal\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    22040\n",
       "1     5710\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_norm['shares_binary'] = np.where(df_train_norm['shares'] >=df_train_norm['shares'].mean(), 1, 0)\n",
    "df_train_norm['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 22087    1\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 22087    0\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "Name: shares_binary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the descriptive features\n",
    "x_norm = predictions_train_norm\n",
    "y_norm = df_train_norm.shares_binary\n",
    "print(\"Descriptive features:\\n\", x_norm.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y_norm.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6236036036036036\n",
      "Confusion matrix: \n",
      " [[13852  8188]\n",
      " [ 2257  3453]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.63      0.73     22040\n",
      "          1       0.30      0.60      0.40      5710\n",
      "\n",
      "avg / total       0.74      0.62      0.66     27750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for train data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_norm, x_norm))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_norm, x_norm))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_norm, x_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22087    0.004593\n",
       "9849     0.003266\n",
       "28004    0.003056\n",
       "30837    0.004340\n",
       "22399    0.005759\n",
       "dtype: float64"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_norm = lm_norm.predict(df_test_norm)\n",
    "predictions_test_norm.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11894.000000\n",
       "mean         0.004018\n",
       "std          0.001802\n",
       "min         -0.000883\n",
       "25%          0.002762\n",
       "50%          0.003688\n",
       "75%          0.004940\n",
       "max          0.026717\n",
       "dtype: float64"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6861\n",
       "1    5033\n",
       "dtype: int64"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_norm = predictions_test_norm.apply(lambda res: 1 if res > predictions_test_norm.mean()  else 0)\n",
    "predictions_test_norm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjal\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9408\n",
       "1    2486\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_norm['shares_binary'] = np.where(df_test_norm['shares'] >=df_test_norm['shares'].mean(), 1, 0)\n",
    "df_test_norm['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 22087    1\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 22087    0\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "Name: shares_binary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the descriptive features\n",
    "x_norm = predictions_test_norm\n",
    "y_norm = df_test_norm.shares_binary\n",
    "print(\"Descriptive features:\\n\", x_norm.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y_norm.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6212375987893055\n",
      "Confusion matrix: \n",
      " [[5882 3526]\n",
      " [ 979 1507]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.63      0.72      9408\n",
      "          1       0.30      0.61      0.40      2486\n",
      "\n",
      "avg / total       0.74      0.62      0.66     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for test data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_norm, x_norm))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_norm, x_norm))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_norm, x_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22087</th>\n",
       "      <td>-0.277967</td>\n",
       "      <td>-0.188620</td>\n",
       "      <td>-0.542370</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>-0.306175</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>0.294896</td>\n",
       "      <td>1.454187</td>\n",
       "      <td>4.229260</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>-0.176245</td>\n",
       "      <td>-0.132503</td>\n",
       "      <td>-0.234752</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>-0.642195</td>\n",
       "      <td>-0.982144</td>\n",
       "      <td>0.204095</td>\n",
       "      <td>0.438508</td>\n",
       "      <td>-0.050599</td>\n",
       "      <td>-0.178641</td>\n",
       "      <td>-0.140500</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>2.081338</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>2.407391</td>\n",
       "      <td>-0.088065</td>\n",
       "      <td>-0.695742</td>\n",
       "      <td>-0.690062</td>\n",
       "      <td>-0.739008</td>\n",
       "      <td>0.321929</td>\n",
       "      <td>-0.354217</td>\n",
       "      <td>-0.301835</td>\n",
       "      <td>0.370014</td>\n",
       "      <td>-0.300464</td>\n",
       "      <td>0.557561</td>\n",
       "      <td>0.112692</td>\n",
       "      <td>-0.870957</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>-0.077669</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>-0.183488</td>\n",
       "      <td>-0.870796</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>0.837738</td>\n",
       "      <td>-0.689649</td>\n",
       "      <td>-0.227693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>0.889364</td>\n",
       "      <td>1.230466</td>\n",
       "      <td>-0.302510</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.011181</td>\n",
       "      <td>0.539737</td>\n",
       "      <td>-0.335562</td>\n",
       "      <td>-0.426520</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>0.567249</td>\n",
       "      <td>-0.117209</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>1.924658</td>\n",
       "      <td>-0.317475</td>\n",
       "      <td>-0.262041</td>\n",
       "      <td>-0.388350</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>-0.199821</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>-0.385932</td>\n",
       "      <td>-0.688937</td>\n",
       "      <td>-0.160130</td>\n",
       "      <td>-0.231337</td>\n",
       "      <td>-0.229797</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>2.440024</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.593317</td>\n",
       "      <td>-0.512883</td>\n",
       "      <td>2.372504</td>\n",
       "      <td>-0.661261</td>\n",
       "      <td>-0.710468</td>\n",
       "      <td>-0.279835</td>\n",
       "      <td>-0.912817</td>\n",
       "      <td>-1.421415</td>\n",
       "      <td>-0.848407</td>\n",
       "      <td>-0.081404</td>\n",
       "      <td>0.290734</td>\n",
       "      <td>-1.919255</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>-2.045023</td>\n",
       "      <td>-1.447792</td>\n",
       "      <td>-0.498547</td>\n",
       "      <td>-0.620369</td>\n",
       "      <td>-0.870796</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>0.837738</td>\n",
       "      <td>-0.689649</td>\n",
       "      <td>-0.228812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>-0.758907</td>\n",
       "      <td>-1.134677</td>\n",
       "      <td>-0.378926</td>\n",
       "      <td>-0.032659</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.048597</td>\n",
       "      <td>-0.519209</td>\n",
       "      <td>0.442620</td>\n",
       "      <td>-0.306175</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>-0.494791</td>\n",
       "      <td>-1.164806</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>2.096799</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>-0.074897</td>\n",
       "      <td>-0.134615</td>\n",
       "      <td>-0.112309</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>1.330978</td>\n",
       "      <td>0.779681</td>\n",
       "      <td>-0.345625</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.136724</td>\n",
       "      <td>0.087034</td>\n",
       "      <td>0.049493</td>\n",
       "      <td>2.225204</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.549856</td>\n",
       "      <td>-0.460849</td>\n",
       "      <td>-0.624926</td>\n",
       "      <td>-0.622545</td>\n",
       "      <td>2.095433</td>\n",
       "      <td>0.063061</td>\n",
       "      <td>0.512317</td>\n",
       "      <td>0.377012</td>\n",
       "      <td>-0.279389</td>\n",
       "      <td>0.476204</td>\n",
       "      <td>-0.388463</td>\n",
       "      <td>-0.484537</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.981786</td>\n",
       "      <td>0.906583</td>\n",
       "      <td>1.109044</td>\n",
       "      <td>0.378217</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>-0.751322</td>\n",
       "      <td>-0.689649</td>\n",
       "      <td>-0.145815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30837</th>\n",
       "      <td>-0.969027</td>\n",
       "      <td>1.703495</td>\n",
       "      <td>-0.228217</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.033201</td>\n",
       "      <td>-0.607455</td>\n",
       "      <td>-0.335562</td>\n",
       "      <td>-0.426520</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>0.262542</td>\n",
       "      <td>-0.117209</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>2.148853</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>-0.013984</td>\n",
       "      <td>-0.062955</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>1.738694</td>\n",
       "      <td>-0.060826</td>\n",
       "      <td>0.776040</td>\n",
       "      <td>0.288836</td>\n",
       "      <td>0.282025</td>\n",
       "      <td>0.388178</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>2.110742</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.593306</td>\n",
       "      <td>2.754187</td>\n",
       "      <td>-0.665429</td>\n",
       "      <td>-0.660721</td>\n",
       "      <td>-0.229194</td>\n",
       "      <td>0.319755</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.990297</td>\n",
       "      <td>-0.081404</td>\n",
       "      <td>0.290734</td>\n",
       "      <td>1.000884</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.981786</td>\n",
       "      <td>-0.598067</td>\n",
       "      <td>-0.785617</td>\n",
       "      <td>0.078641</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.107646</td>\n",
       "      <td>-0.751322</td>\n",
       "      <td>-0.247747</td>\n",
       "      <td>0.507839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22399</th>\n",
       "      <td>-0.305983</td>\n",
       "      <td>1.230466</td>\n",
       "      <td>-0.389539</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>-0.872192</td>\n",
       "      <td>-0.854350</td>\n",
       "      <td>-0.546866</td>\n",
       "      <td>-0.060828</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>-0.641007</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>2.309718</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>0.115617</td>\n",
       "      <td>0.295866</td>\n",
       "      <td>-0.234752</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>0.923015</td>\n",
       "      <td>-0.982144</td>\n",
       "      <td>2.415166</td>\n",
       "      <td>2.005859</td>\n",
       "      <td>-0.202585</td>\n",
       "      <td>-0.251763</td>\n",
       "      <td>-0.264409</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>2.089123</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>1.329639</td>\n",
       "      <td>-0.491186</td>\n",
       "      <td>-0.648470</td>\n",
       "      <td>-0.079070</td>\n",
       "      <td>-0.122468</td>\n",
       "      <td>0.562803</td>\n",
       "      <td>0.982511</td>\n",
       "      <td>0.887710</td>\n",
       "      <td>-0.516526</td>\n",
       "      <td>0.794837</td>\n",
       "      <td>-0.776576</td>\n",
       "      <td>-0.010914</td>\n",
       "      <td>-0.870957</td>\n",
       "      <td>-0.228938</td>\n",
       "      <td>0.179424</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>0.378217</td>\n",
       "      <td>0.531052</td>\n",
       "      <td>0.244634</td>\n",
       "      <td>-1.569929</td>\n",
       "      <td>-0.087055</td>\n",
       "      <td>0.008998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29327</th>\n",
       "      <td>-0.856963</td>\n",
       "      <td>3.122581</td>\n",
       "      <td>0.204805</td>\n",
       "      <td>-0.026303</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.036065</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.335562</td>\n",
       "      <td>-0.306175</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>-0.233018</td>\n",
       "      <td>-0.117209</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>2.148853</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>-0.137883</td>\n",
       "      <td>-0.284748</td>\n",
       "      <td>-0.234752</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>-0.326709</td>\n",
       "      <td>-0.982144</td>\n",
       "      <td>-0.349419</td>\n",
       "      <td>-1.042769</td>\n",
       "      <td>-0.121526</td>\n",
       "      <td>-0.210327</td>\n",
       "      <td>-0.196259</td>\n",
       "      <td>2.225204</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.593297</td>\n",
       "      <td>2.582047</td>\n",
       "      <td>-0.665287</td>\n",
       "      <td>-0.061260</td>\n",
       "      <td>-0.710470</td>\n",
       "      <td>0.163058</td>\n",
       "      <td>0.717314</td>\n",
       "      <td>0.581909</td>\n",
       "      <td>-0.241529</td>\n",
       "      <td>0.517005</td>\n",
       "      <td>-0.438160</td>\n",
       "      <td>1.277354</td>\n",
       "      <td>-0.461973</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>-0.495714</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>-0.503867</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.735510</td>\n",
       "      <td>-0.751322</td>\n",
       "      <td>0.488758</td>\n",
       "      <td>-0.206020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35443</th>\n",
       "      <td>-1.309888</td>\n",
       "      <td>0.284409</td>\n",
       "      <td>0.102918</td>\n",
       "      <td>-0.018810</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.020780</td>\n",
       "      <td>0.363246</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.175205</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>-0.032249</td>\n",
       "      <td>-0.117209</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>2.096799</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>-0.192834</td>\n",
       "      <td>-0.331279</td>\n",
       "      <td>0.229153</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>1.863379</td>\n",
       "      <td>0.939826</td>\n",
       "      <td>-0.205425</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>-0.151923</td>\n",
       "      <td>-0.185953</td>\n",
       "      <td>-0.180426</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>3.672075</td>\n",
       "      <td>2.576503</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>-0.512479</td>\n",
       "      <td>-0.081944</td>\n",
       "      <td>-0.661136</td>\n",
       "      <td>1.082855</td>\n",
       "      <td>0.187158</td>\n",
       "      <td>1.526429</td>\n",
       "      <td>1.776580</td>\n",
       "      <td>-1.378993</td>\n",
       "      <td>1.548813</td>\n",
       "      <td>-1.694958</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>-0.870957</td>\n",
       "      <td>0.981786</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>1.223872</td>\n",
       "      <td>-0.620369</td>\n",
       "      <td>0.671237</td>\n",
       "      <td>1.614519</td>\n",
       "      <td>-1.810696</td>\n",
       "      <td>1.519864</td>\n",
       "      <td>-0.008203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16627</th>\n",
       "      <td>0.254336</td>\n",
       "      <td>0.284409</td>\n",
       "      <td>0.085936</td>\n",
       "      <td>-0.014180</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.519209</td>\n",
       "      <td>-0.594956</td>\n",
       "      <td>-0.426520</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>-0.076294</td>\n",
       "      <td>0.930389</td>\n",
       "      <td>4.229260</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.317475</td>\n",
       "      <td>-0.103928</td>\n",
       "      <td>-0.095632</td>\n",
       "      <td>-0.234752</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>-0.694978</td>\n",
       "      <td>-0.982144</td>\n",
       "      <td>-0.213120</td>\n",
       "      <td>-0.394999</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>-0.183516</td>\n",
       "      <td>-0.148761</td>\n",
       "      <td>2.225204</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.615289</td>\n",
       "      <td>-0.541748</td>\n",
       "      <td>-0.291371</td>\n",
       "      <td>-0.682597</td>\n",
       "      <td>1.952262</td>\n",
       "      <td>0.264168</td>\n",
       "      <td>0.095324</td>\n",
       "      <td>0.072354</td>\n",
       "      <td>-0.590208</td>\n",
       "      <td>0.619589</td>\n",
       "      <td>-0.563114</td>\n",
       "      <td>-0.056214</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>-0.632512</td>\n",
       "      <td>0.360916</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>-0.183488</td>\n",
       "      <td>-0.870796</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>0.837738</td>\n",
       "      <td>-0.689649</td>\n",
       "      <td>0.008998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16655</th>\n",
       "      <td>0.249667</td>\n",
       "      <td>0.757438</td>\n",
       "      <td>0.238768</td>\n",
       "      <td>-0.016802</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.004710</td>\n",
       "      <td>1.069210</td>\n",
       "      <td>1.480195</td>\n",
       "      <td>1.137967</td>\n",
       "      <td>-0.304264</td>\n",
       "      <td>-0.120924</td>\n",
       "      <td>0.406590</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>2.148853</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.389280</td>\n",
       "      <td>-0.130366</td>\n",
       "      <td>-0.091720</td>\n",
       "      <td>-0.234752</td>\n",
       "      <td>0.424126</td>\n",
       "      <td>-0.668156</td>\n",
       "      <td>-0.982144</td>\n",
       "      <td>-0.317980</td>\n",
       "      <td>-0.661673</td>\n",
       "      <td>-0.153189</td>\n",
       "      <td>-0.198140</td>\n",
       "      <td>-0.199357</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>2.089123</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.606895</td>\n",
       "      <td>-0.527476</td>\n",
       "      <td>-0.677993</td>\n",
       "      <td>2.289362</td>\n",
       "      <td>-0.722699</td>\n",
       "      <td>0.355242</td>\n",
       "      <td>0.595868</td>\n",
       "      <td>0.077248</td>\n",
       "      <td>0.287662</td>\n",
       "      <td>-0.037592</td>\n",
       "      <td>0.237368</td>\n",
       "      <td>0.418258</td>\n",
       "      <td>-0.461973</td>\n",
       "      <td>0.578211</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>0.420076</td>\n",
       "      <td>0.602899</td>\n",
       "      <td>1.596456</td>\n",
       "      <td>1.237801</td>\n",
       "      <td>-0.221636</td>\n",
       "      <td>1.077961</td>\n",
       "      <td>-0.240164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>1.127499</td>\n",
       "      <td>-0.188620</td>\n",
       "      <td>-0.879873</td>\n",
       "      <td>0.049666</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.038219</td>\n",
       "      <td>-0.430964</td>\n",
       "      <td>-0.854350</td>\n",
       "      <td>-0.546866</td>\n",
       "      <td>-0.060828</td>\n",
       "      <td>-0.209647</td>\n",
       "      <td>-0.641007</td>\n",
       "      <td>-0.236442</td>\n",
       "      <td>-0.465353</td>\n",
       "      <td>-0.432942</td>\n",
       "      <td>-0.249484</td>\n",
       "      <td>-0.476905</td>\n",
       "      <td>-0.519560</td>\n",
       "      <td>-0.317475</td>\n",
       "      <td>-0.210978</td>\n",
       "      <td>-0.226112</td>\n",
       "      <td>-0.234752</td>\n",
       "      <td>-0.288687</td>\n",
       "      <td>0.572786</td>\n",
       "      <td>-0.982144</td>\n",
       "      <td>-0.127510</td>\n",
       "      <td>-0.317523</td>\n",
       "      <td>-0.202585</td>\n",
       "      <td>-0.251763</td>\n",
       "      <td>-0.264409</td>\n",
       "      <td>-0.449386</td>\n",
       "      <td>-0.478658</td>\n",
       "      <td>2.081338</td>\n",
       "      <td>-0.473755</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.256817</td>\n",
       "      <td>-0.272319</td>\n",
       "      <td>-0.388113</td>\n",
       "      <td>-0.575207</td>\n",
       "      <td>-0.490967</td>\n",
       "      <td>-0.648557</td>\n",
       "      <td>2.177717</td>\n",
       "      <td>-0.694008</td>\n",
       "      <td>1.837620</td>\n",
       "      <td>2.194055</td>\n",
       "      <td>-0.100182</td>\n",
       "      <td>-0.834553</td>\n",
       "      <td>0.794837</td>\n",
       "      <td>-0.776576</td>\n",
       "      <td>1.419980</td>\n",
       "      <td>0.573766</td>\n",
       "      <td>0.981786</td>\n",
       "      <td>0.563897</td>\n",
       "      <td>1.152104</td>\n",
       "      <td>-0.838809</td>\n",
       "      <td>-0.253983</td>\n",
       "      <td>0.107646</td>\n",
       "      <td>-0.221636</td>\n",
       "      <td>-0.247747</td>\n",
       "      <td>8.067861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "22087  -0.277967       -0.188620         -0.542370         0.010384   \n",
       "9849    0.889364        1.230466         -0.302510         0.000327   \n",
       "28004  -0.758907       -1.134677         -0.378926        -0.032659   \n",
       "30837  -0.969027        1.703495         -0.228217         0.007624   \n",
       "22399  -0.305983        1.230466         -0.389539         0.013601   \n",
       "29327  -0.856963        3.122581          0.204805        -0.026303   \n",
       "35443  -1.309888        0.284409          0.102918        -0.018810   \n",
       "16627   0.254336        0.284409          0.085936        -0.014180   \n",
       "16655   0.249667        0.757438          0.238768        -0.016802   \n",
       "7224    1.127499       -0.188620         -0.879873         0.049666   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "22087          0.000675                  0.031704  -0.166227        0.183226   \n",
       "9849           0.000675                 -0.011181   0.539737       -0.335562   \n",
       "28004          0.000675                 -0.048597  -0.519209        0.442620   \n",
       "30837          0.000675                  0.033201  -0.607455       -0.335562   \n",
       "22399          0.000675                  0.019308  -0.872192       -0.854350   \n",
       "29327          0.000675                 -0.036065  -0.166227       -0.335562   \n",
       "35443          0.000675                 -0.020780   0.363246        0.183226   \n",
       "16627          0.000675                 -0.000346  -0.519209       -0.594956   \n",
       "16655          0.000675                 -0.004710   1.069210        1.480195   \n",
       "7224           0.000675                  0.038219  -0.430964       -0.854350   \n",
       "\n",
       "       num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "22087 -0.306175   -0.304264              0.294896      1.454187   \n",
       "9849  -0.426520   -0.304264              0.567249     -0.117209   \n",
       "28004 -0.306175   -0.304264             -0.494791     -1.164806   \n",
       "30837 -0.426520   -0.304264              0.262542     -0.117209   \n",
       "22399 -0.546866   -0.060828              0.013014     -0.641007   \n",
       "29327 -0.306175   -0.304264             -0.233018     -0.117209   \n",
       "35443  0.175205   -0.304264             -0.032249     -0.117209   \n",
       "16627 -0.426520   -0.304264             -0.076294      0.930389   \n",
       "16655  1.137967   -0.304264             -0.120924      0.406590   \n",
       "7224  -0.546866   -0.060828             -0.209647     -0.641007   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "22087                   4.229260                      -0.465353   \n",
       "9849                   -0.236442                      -0.465353   \n",
       "28004                  -0.236442                      -0.465353   \n",
       "30837                  -0.236442                       2.148853   \n",
       "22399                  -0.236442                      -0.465353   \n",
       "29327                  -0.236442                       2.148853   \n",
       "35443                  -0.236442                      -0.465353   \n",
       "16627                   4.229260                      -0.465353   \n",
       "16655                  -0.236442                       2.148853   \n",
       "7224                   -0.236442                      -0.465353   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "22087            -0.432942               -0.249484             -0.476905   \n",
       "9849             -0.432942               -0.249484             -0.476905   \n",
       "28004            -0.432942               -0.249484              2.096799   \n",
       "30837            -0.432942               -0.249484             -0.476905   \n",
       "22399             2.309718               -0.249484             -0.476905   \n",
       "29327            -0.432942               -0.249484             -0.476905   \n",
       "35443            -0.432942               -0.249484              2.096799   \n",
       "16627            -0.432942               -0.249484             -0.476905   \n",
       "16655            -0.432942               -0.249484             -0.476905   \n",
       "7224             -0.432942               -0.249484             -0.476905   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "22087              -0.519560   -0.389280   -0.176245   -0.132503   -0.234752   \n",
       "9849                1.924658   -0.317475   -0.262041   -0.388350   -0.008836   \n",
       "28004              -0.519560   -0.389280   -0.074897   -0.134615   -0.112309   \n",
       "30837              -0.519560   -0.389280   -0.013984   -0.062955    0.001512   \n",
       "22399              -0.519560   -0.389280    0.115617    0.295866   -0.234752   \n",
       "29327              -0.519560   -0.389280   -0.137883   -0.284748   -0.234752   \n",
       "35443              -0.519560   -0.389280   -0.192834   -0.331279    0.229153   \n",
       "16627              -0.519560   -0.317475   -0.103928   -0.095632   -0.234752   \n",
       "16655              -0.519560   -0.389280   -0.130366   -0.091720   -0.234752   \n",
       "7224               -0.519560   -0.317475   -0.210978   -0.226112   -0.234752   \n",
       "\n",
       "       kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  kw_avg_avg  \\\n",
       "22087    0.424126   -0.642195   -0.982144    0.204095    0.438508   \n",
       "9849     0.424126   -0.199821    0.220930   -0.385932   -0.688937   \n",
       "28004    0.424126    1.330978    0.779681   -0.345625   -0.303173   \n",
       "30837    0.424126    0.000980    1.738694   -0.060826    0.776040   \n",
       "22399    0.424126    0.923015   -0.982144    2.415166    2.005859   \n",
       "29327    0.424126   -0.326709   -0.982144   -0.349419   -1.042769   \n",
       "35443    0.424126    1.863379    0.939826   -0.205425    0.026980   \n",
       "16627    0.424126   -0.694978   -0.982144   -0.213120   -0.394999   \n",
       "16655    0.424126   -0.668156   -0.982144   -0.317980   -0.661673   \n",
       "7224    -0.288687    0.572786   -0.982144   -0.127510   -0.317523   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "22087                  -0.050599                  -0.178641   \n",
       "9849                   -0.160130                  -0.231337   \n",
       "28004                  -0.136724                   0.087034   \n",
       "30837                   0.288836                   0.282025   \n",
       "22399                  -0.202585                  -0.251763   \n",
       "29327                  -0.121526                  -0.210327   \n",
       "35443                  -0.151923                  -0.185953   \n",
       "16627                  -0.060731                  -0.183516   \n",
       "16655                  -0.153189                  -0.198140   \n",
       "7224                   -0.202585                  -0.251763   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "22087                   -0.140500          -0.449386           -0.478658   \n",
       "9849                    -0.229797          -0.449386           -0.478658   \n",
       "28004                    0.049493           2.225204           -0.478658   \n",
       "30837                    0.388178          -0.449386           -0.478658   \n",
       "22399                   -0.264409          -0.449386            2.089123   \n",
       "29327                   -0.196259           2.225204           -0.478658   \n",
       "35443                   -0.180426          -0.449386           -0.478658   \n",
       "16627                   -0.148761           2.225204           -0.478658   \n",
       "16655                   -0.199357          -0.449386            2.089123   \n",
       "7224                    -0.264409          -0.449386           -0.478658   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "22087              2.081338            -0.473755          -0.409822   \n",
       "9849              -0.480448            -0.473755           2.440024   \n",
       "28004             -0.480448            -0.473755          -0.409822   \n",
       "30837             -0.480448             2.110742          -0.409822   \n",
       "22399             -0.480448            -0.473755          -0.409822   \n",
       "29327             -0.480448            -0.473755          -0.409822   \n",
       "35443             -0.480448            -0.473755          -0.409822   \n",
       "16627             -0.480448            -0.473755          -0.409822   \n",
       "16655             -0.480448            -0.473755          -0.409822   \n",
       "7224               2.081338            -0.473755          -0.409822   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "22087            -0.256817          -0.272319   -0.388113  2.407391 -0.088065   \n",
       "9849             -0.256817          -0.272319   -0.388113 -0.593317 -0.512883   \n",
       "28004            -0.256817          -0.272319   -0.388113 -0.549856 -0.460849   \n",
       "30837            -0.256817          -0.272319   -0.388113 -0.593306  2.754187   \n",
       "22399            -0.256817          -0.272319   -0.388113  1.329639 -0.491186   \n",
       "29327            -0.256817          -0.272319   -0.388113 -0.593297  2.582047   \n",
       "35443            -0.256817           3.672075    2.576503  0.067527 -0.512479   \n",
       "16627            -0.256817          -0.272319   -0.388113 -0.615289 -0.541748   \n",
       "16655            -0.256817          -0.272319   -0.388113 -0.606895 -0.527476   \n",
       "7224             -0.256817          -0.272319   -0.388113 -0.575207 -0.490967   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "22087 -0.695742 -0.690062 -0.739008             0.321929   \n",
       "9849   2.372504 -0.661261 -0.710468            -0.279835   \n",
       "28004 -0.624926 -0.622545  2.095433             0.063061   \n",
       "30837 -0.665429 -0.660721 -0.229194             0.319755   \n",
       "22399 -0.648470 -0.079070 -0.122468             0.562803   \n",
       "29327 -0.665287 -0.061260 -0.710470             0.163058   \n",
       "35443 -0.081944 -0.661136  1.082855             0.187158   \n",
       "16627 -0.291371 -0.682597  1.952262             0.264168   \n",
       "16655 -0.677993  2.289362 -0.722699             0.355242   \n",
       "7224  -0.648557  2.177717 -0.694008             1.837620   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "22087                  -0.354217                   -0.301835   \n",
       "9849                   -0.912817                   -1.421415   \n",
       "28004                   0.512317                    0.377012   \n",
       "30837                   0.216002                    0.863226   \n",
       "22399                   0.982511                    0.887710   \n",
       "29327                   0.717314                    0.581909   \n",
       "35443                   1.526429                    1.776580   \n",
       "16627                   0.095324                    0.072354   \n",
       "16655                   0.595868                    0.077248   \n",
       "7224                    2.194055                   -0.100182   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "22087                    0.370014            -0.300464             0.557561   \n",
       "9849                    -0.848407            -0.081404             0.290734   \n",
       "28004                   -0.279389             0.476204            -0.388463   \n",
       "30837                    0.990297            -0.081404             0.290734   \n",
       "22399                   -0.516526             0.794837            -0.776576   \n",
       "29327                   -0.241529             0.517005            -0.438160   \n",
       "35443                   -1.378993             1.548813            -1.694958   \n",
       "16627                   -0.590208             0.619589            -0.563114   \n",
       "16655                    0.287662            -0.037592             0.237368   \n",
       "7224                    -0.834553             0.794837            -0.776576   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "22087               0.112692              -0.870957               0.174637   \n",
       "9849               -1.919255               0.063864              -2.045023   \n",
       "28004              -0.484537               0.063864               0.981786   \n",
       "30837               1.000884               0.063864               0.981786   \n",
       "22399              -0.010914              -0.870957              -0.228938   \n",
       "29327               1.277354              -0.461973               0.174637   \n",
       "35443               0.020005              -0.870957               0.981786   \n",
       "16627              -0.056214               0.063864              -0.632512   \n",
       "16655               0.418258              -0.461973               0.578211   \n",
       "7224                1.419980               0.573766               0.981786   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "22087              -0.077669               0.075593              -0.183488   \n",
       "9849               -1.447792              -0.498547              -0.620369   \n",
       "28004               0.906583               1.109044               0.378217   \n",
       "30837              -0.598067              -0.785617               0.078641   \n",
       "22399               0.179424               0.075593               0.378217   \n",
       "29327              -0.495714               0.075593              -0.503867   \n",
       "35443               0.727007               1.223872              -0.620369   \n",
       "16627               0.360916               0.075593              -0.183488   \n",
       "16655               0.624600               0.420076               0.602899   \n",
       "7224                0.563897               1.152104              -0.838809   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "22087           -0.870796                 -0.269073                0.837738   \n",
       "9849            -0.870796                 -0.269073                0.837738   \n",
       "28004            0.054424                 -0.269073               -0.751322   \n",
       "30837            0.054424                  0.107646               -0.751322   \n",
       "22399            0.531052                  0.244634               -1.569929   \n",
       "29327            0.054424                  0.735510               -0.751322   \n",
       "35443            0.671237                  1.614519               -1.810696   \n",
       "16627           -0.870796                 -0.269073                0.837738   \n",
       "16655            1.596456                  1.237801               -0.221636   \n",
       "7224            -0.253983                  0.107646               -0.221636   \n",
       "\n",
       "       abs_title_sentiment_polarity    shares  \n",
       "22087                     -0.689649 -0.227693  \n",
       "9849                      -0.689649 -0.228812  \n",
       "28004                     -0.689649 -0.145815  \n",
       "30837                     -0.247747  0.507839  \n",
       "22399                     -0.087055  0.008998  \n",
       "29327                      0.488758 -0.206020  \n",
       "35443                      1.519864 -0.008203  \n",
       "16627                     -0.689649  0.008998  \n",
       "16655                      1.077961 -0.240164  \n",
       "7224                      -0.247747  8.067861  "
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying standardisation of features, instead of range normalisation.\n",
    "df_st = (df_cont - df_cont.mean()) / df_cont.std()\n",
    "df_st.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_st=df_st.head(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_st=df_st.head(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 shares   R-squared:                       0.018\n",
      "Model:                            OLS   Adj. R-squared:                  0.018\n",
      "Method:                 Least Squares   F-statistic:                     25.78\n",
      "Date:                Mon, 30 Apr 2018   Prob (F-statistic):           1.36e-95\n",
      "Time:                        00:44:32   Log-Likelihood:                -38391.\n",
      "No. Observations:               27750   AIC:                         7.682e+04\n",
      "Df Residuals:                   27729   BIC:                         7.700e+04\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                     -0.0017      0.006     -0.291      0.771      -0.013       0.010\n",
      "LDA_00                         6.6162     36.892      0.179      0.858     -65.694      78.926\n",
      "LDA_01                         5.5072     30.821      0.179      0.858     -54.904      65.919\n",
      "LDA_02                         7.0815     39.582      0.179      0.858     -70.501      84.664\n",
      "LDA_03                         7.4508     41.411      0.180      0.857     -73.716      88.618\n",
      "LDA_04                         7.2732     40.568      0.179      0.858     -72.241      86.788\n",
      "average_token_length          -0.0129      0.020     -0.654      0.513      -0.052       0.026\n",
      "avg_negative_polarity         -0.0183      0.008     -2.372      0.018      -0.033      -0.003\n",
      "avg_positive_polarity         -0.0210      0.009     -2.273      0.023      -0.039      -0.003\n",
      "global_rate_positive_words    -0.0209      0.008     -2.484      0.013      -0.037      -0.004\n",
      "global_sentiment_polarity      0.0206      0.009      2.175      0.030       0.002       0.039\n",
      "global_subjectivity            0.0305      0.010      3.192      0.001       0.012       0.049\n",
      "kw_avg_avg                     0.1602      0.014     11.475      0.000       0.133       0.188\n",
      "kw_avg_max                    -0.0297      0.008     -3.815      0.000      -0.045      -0.014\n",
      "kw_avg_min                    -0.0163      0.017     -0.964      0.335      -0.049       0.017\n",
      "kw_max_avg                    -0.0782      0.012     -6.292      0.000      -0.103      -0.054\n",
      "kw_max_min                     0.0206      0.018      1.177      0.239      -0.014       0.055\n",
      "n_non_stop_unique_tokens      -0.9618      0.472     -2.036      0.042      -1.888      -0.036\n",
      "n_non_stop_words              -0.3846      0.734     -0.524      0.600      -1.824       1.055\n",
      "n_tokens_content               0.0314      0.009      3.376      0.001       0.013       0.050\n",
      "n_unique_tokens                1.4737      0.603      2.443      0.015       0.291       2.656\n",
      "==============================================================================\n",
      "Omnibus:                    76873.309   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       4791467428.715\n",
      "Skew:                          35.302   Prob(JB):                         0.00\n",
      "Kurtosis:                    2037.450   Cond. No.                     3.04e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.04e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Train a model \n",
    "lm_st= sm.ols(formula=\"shares ~  LDA_00 + LDA_01 + LDA_02 + LDA_03 + LDA_04 + average_token_length + avg_negative_polarity + avg_positive_polarity +  global_rate_positive_words + global_sentiment_polarity + global_subjectivity + kw_avg_avg + kw_avg_max + kw_avg_min + kw_max_avg + kw_max_min  + n_non_stop_unique_tokens + n_non_stop_words + n_tokens_content + n_unique_tokens \", data=df_train_st).fit()\n",
    "print(lm_st.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22087    0.041202\n",
       "9849    -0.055026\n",
       "28004   -0.070325\n",
       "30837    0.022873\n",
       "22399    0.125741\n",
       "dtype: float64"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_st = lm_st.predict(df_train_st)\n",
    "predictions_train_st.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27750.000000\n",
       "mean        -0.001293\n",
       "std          0.131623\n",
       "min         -0.355956\n",
       "25%         -0.093411\n",
       "50%         -0.025630\n",
       "75%          0.066461\n",
       "max          2.035796\n",
       "dtype: float64"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_st.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16109\n",
       "1    11641\n",
       "dtype: int64"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_st = predictions_train_st.apply(lambda res: 1 if res > predictions_train_st.mean()  else 0)\n",
    "predictions_train_st.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjal\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    22040\n",
       "1     5710\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_st['shares_binary'] = np.where(df_train_st['shares'] >=df_train_st['shares'].mean(), 1, 0)\n",
    "df_train_st['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 22087    1\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 22087    0\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "Name: shares_binary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x_st = predictions_test_st\n",
    "y_st = df_test_st.shares_binary\n",
    "print(\"Descriptive features:\\n\", x_st.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y_st.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6212375987893055\n",
      "Confusion matrix: \n",
      " [[5882 3526]\n",
      " [ 979 1507]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.63      0.72      9408\n",
      "          1       0.30      0.61      0.40      2486\n",
      "\n",
      "avg / total       0.74      0.62      0.66     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for train data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_st, x_st))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_st, x_st))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_st, x_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22087    0.041202\n",
       "9849    -0.055026\n",
       "28004   -0.070325\n",
       "30837    0.022873\n",
       "22399    0.125741\n",
       "dtype: float64"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_st = lm_st.predict(df_test_st)\n",
    "predictions_test_st.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11894.000000\n",
       "mean        -0.000489\n",
       "std          0.130705\n",
       "min         -0.355956\n",
       "25%         -0.091599\n",
       "50%         -0.024486\n",
       "75%          0.066346\n",
       "max          1.645840\n",
       "dtype: float64"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_st.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6861\n",
       "1    5033\n",
       "dtype: int64"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_st = predictions_test_st.apply(lambda res: 1 if res > predictions_test_st.mean()  else 0)\n",
    "predictions_test_st.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjal\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9408\n",
       "1    2486\n",
       "Name: shares_binary, dtype: int64"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_st['shares_binary'] = np.where(df_test_st['shares'] >=df_test_st['shares'].mean(), 1, 0)\n",
    "df_test_st['shares_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      " 22087    1\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "dtype: int64\n",
      "\n",
      "Target feature:\n",
      " 22087    0\n",
      "9849     0\n",
      "28004    0\n",
      "30837    1\n",
      "Name: shares_binary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features\n",
    "x_st = predictions_test_st\n",
    "y_st = df_test_st.shares_binary\n",
    "print(\"Descriptive features:\\n\", x_st.head(4))\n",
    "print(\"\\nTarget feature:\\n\", y_st.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6212375987893055\n",
      "Confusion matrix: \n",
      " [[5882 3526]\n",
      " [ 979 1507]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.63      0.72      9408\n",
      "          1       0.30      0.61      0.40      2486\n",
      "\n",
      "avg / total       0.74      0.62      0.66     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics for test data\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_st, x_st))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_st, x_st))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_st, x_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation: Training versus test error\n",
    "Evaluating the model quality only on the training data is misleading. This happens due to the fact that more complex models (e.g., more features) can fit the training data better, but do not generalise to new data, since they pick up too many unimportant details from the training data.\n",
    "The more complexity we add to the model, the lower the training error tends to get, and the higher the test error. This is called over-fitting the data. An example is shown in the picture below.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Actual - Predicted:\\n', 8246    -1491.405290\n",
      "30971    3592.731392\n",
      "23069   -4490.972075\n",
      "8805    -2116.383307\n",
      "9696    -3793.222320\n",
      "dtype: float64)\n",
      "\n",
      "(Actual - Predicted) squared:\n",
      " 8246     2.224290e+06\n",
      "30971    1.290772e+07\n",
      "23069    2.016883e+07\n",
      "8805     4.479078e+06\n",
      "9696     1.438854e+07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Pair the actual and the predicted values\n",
    "print((\"Actual - Predicted:\\n\", (df_train.shares - lm2.predict(df_train)).head(5)))\n",
    "print(\"\\n(Actual - Predicted) squared:\\n\", ((df_train.shares - lm2.predict(df_train))**2).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Squared Error:\n",
      " 109106818.34973353\n"
     ]
    }
   ],
   "source": [
    "# Print the Mean Squared Error of the model on the training set\n",
    "mse = ((df_train.shares - lm2.predict(df_train))** 2).mean()\n",
    "print(\"\\nMean Squared Error:\\n\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Absolute Error:\n",
      " 3057.458072787482\n"
     ]
    }
   ],
   "source": [
    "# Print the Mean Absolute Error of the model on the training set\n",
    "mae = abs(df_train.shares - lm2.predict(df_train)).mean()\n",
    "print(\"\\nMean Absolute Error:\\n\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Squared Error:\n",
      " 126309806.43748417\n"
     ]
    }
   ],
   "source": [
    "# Print the Mean Squared Error of the model on the test set\n",
    "mse = ((df_test.shares - lm2.predict(df_test))** 2).mean()\n",
    "print(\"\\nMean Squared Error:\\n\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Absolute Error:\n",
      " 3159.3925534524687\n"
     ]
    }
   ],
   "source": [
    "# Print the Mean Absolute Error of the model on the training set\n",
    "mae = abs(df_test.shares - lm2.predict(df_test)).mean()\n",
    "print(\"\\nMean Absolute Error:\\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:\n",
    "\n",
    "\n",
    "To perform the linear regression we started with data preparation and data understanding by dropping unimportant columns. The cleaned dataset is used to evaluate the linear regression model. As the next step, we experimented using different methods to choose appropriate features that impacts the prediction of target shares.\n",
    "\n",
    "\n",
    "- We tested the performance of the model by selecting the features manually. This gave pretty good results and similar accuracy which is around 0.63 for mean threshold and 0.72 for the 3rd quartile threshold.\n",
    "\n",
    "- Like wise we considered different features based on algorithm information gain. We chose the features for this iteration of the linear model based on the output of this algorithm. We trained the model and split the dataset into a training set and a test set. Fit the model on the training set, evaluated both on the training and the test set. Interestingly, the accuracy is good which is again 0.63 when threshold is set to mean and 0.73 for the higher threshold level.\n",
    "- As suggested by professor during the presentation we tried training the model with all the features which gave adequate results. R-squared value is 0.023 and accuracy while evaluating the train data is around 0.64 and on test data 0.644. We thought of experimenting by setting new threshold value to 75% and evaluated the model which boosted the performance for training model to 0.73 and test model to 0.735.\n",
    "\n",
    "- We have decided to experiment using the random forest metrics to inform our linear regression model. Using the feature importance table from the 100 tree model, we selected the top 10 most important features and ran a linear model using these. We were successful in obtaining the good accuracy which is 0.62 for the mean threshold and 0.72 by setting threshold to third quartile.\n",
    "\n",
    "- We also tried normalizing and standardizing the methods, which gave relatively modest accuracy similar to other models.\n",
    "\n",
    "- Overall its good practice on evaluating the model using different features and assessing the metrics. We can say among all the feature selection methods, the model trained with all the features gave higher accuracyWe will use these results to compare with our further models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
