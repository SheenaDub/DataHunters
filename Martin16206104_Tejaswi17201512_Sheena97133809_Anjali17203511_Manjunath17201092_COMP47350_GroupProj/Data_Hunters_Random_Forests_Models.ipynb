{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import cleaned dataset. Drop non-predictive features and set \n",
    "display options to suit our large amount of features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "# for now, df is created from original dataset\n",
    "# should be replaced by cleaned version once quality plan is complete\n",
    "df = pd.read_csv('OnlineNewsPopularityCleaned.csv', skipinitialspace=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "# could try leaving timedelta in for the random forests, because if it is worthless\n",
    "# random forests algo will just ignore\n",
    "df = df.drop(['url', 'timedelta'], axis=1)\n",
    "# drop non-predictive features \n",
    "shuffle(df)\n",
    "# shuffle df in case there is a pattern to how rows were inserted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split df into X (descriptive features) and y (target feature)\n",
    "X = df.drop(['shares'], axis=1)   \n",
    "y = df['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# further split into training and testing sets for convenient use with sklearn models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> As the target is a continuous value, will first try RandomForestRegressor. Starting with a baseline model, using all predictive features of the dataset, and all default params for the model. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_baseline = RandomForestRegressor(n_estimators=100, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.089992946569479981"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appears to be a very poor score. (from what i understand, oob score is an estimated r2 score when testing the model\n",
    "# on the 'out of bag' rows - those not used in any of the random samples assembled in the bagging process)\n",
    "rf_baseline.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a mean absolute error to get another check of model accuracy (using mae because, from my current understanding,\n",
    "# it's less sensitive to outliers that mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479.3732078853045"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = median_absolute_error(y_test[:500], rf_baseline.oob_prediction_[:500])\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to get perspective on this figure, i will look closer at the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     38463.000000\n",
       "mean       3355.360398\n",
       "std       11585.968776\n",
       "min           1.000000\n",
       "25%         945.000000\n",
       "50%        1400.000000\n",
       "75%        2700.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high std deviation - triple the mean value. \n",
    "# this skewed distribution makes sense, given the nature of the target feature - viral popularity is related to a\n",
    "# network effect which results in something like exponential growth of social media shares past a certain point. \n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2e249d68>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAEKCAYAAAAl5S8KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a235deba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the target feature for clarifications of the distribution pattern discussed above.\n",
    "# the boxplot shows the extremely skewed distribution of the target feature. a large number of samples (covering the \n",
    "# large majority of the range) are classed as outliers. will try removing outliers from the target and use it for \n",
    "# a new model iteration\n",
    "sns.boxplot(x=y[:1000], color='red', fliersize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a247e5b70>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEzgoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24812940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# very strongly right-skewed distribution is apparent. although random forests is said to be relatively insensitive to\n",
    "# outliers, perhaps this case is too extreme. \n",
    "sns.distplot(y[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> New model iteration, using the updated target feature. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop outliers from target (identified in box plot below)\n",
    "df = df.drop(df[df['shares'] > 5000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-assign train test variables to reflect updated df.\n",
    "X = df.drop(['shares'], axis=1)   \n",
    "y = df['shares']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_outliers_dropped = RandomForestRegressor(n_estimators=100, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_outliers_dropped.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737.06616541353389"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = median_absolute_error(y_test[:500], rf_outliers_dropped.oob_prediction_[:500])\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614.346122958865"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# big improvement, but mae still seems very high in relation to the mean\n",
    "df['shares'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.327543424317618"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt to calculate accuracy from mae. fairly poor accuracy rate. \n",
    "mae = median_absolute_error(y_train, rf_outliers_dropped.oob_prediction_)\n",
    "100 - ((mae/y_test.median()) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using a randomised search grid to find the optimal parameters for the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using a randomised search rather than normal grid search to save processing time (will just be testing a \n",
    "# random selection of permutations)\n",
    "# for this project, will just be testing for ideal n_estimators (number of trees) and max_depth (max tree depth)\n",
    "grid = {'n_estimators': [10, 50, 100, 150, 200, 500, 1000], 'max_depth': [2,4,6,10,15,None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please note: the next two cells TAKE APPROX 30 MINS TO RUN. results should be visible on opening the notebook.\n",
    "# n_jobs set to -1 to allow all available cores to help with processing time.\n",
    "rf_reg_random = RandomizedSearchCV(estimator = rf_reg, param_distributions = grid, n_iter = 30, cv=3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 50, 100, 150, 200, 500, 1000], 'max_depth': [2, 4, 6, 10, 15, None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 200}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on the randomised search, the following are considered to be the best parameter settings\n",
    "rf_reg_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model, using optimal params\n",
    "rf_best_params = RandomForestRegressor(n_estimators=200, max_depth=2, oob_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_params.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684.87217697072208"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a further improvement on the mae, but still seems too high.\n",
    "mae = median_absolute_error(y_test[:500], rf_best_params.oob_prediction_[:500])\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>5000</td>\n",
       "      <td>1888.164112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26805</th>\n",
       "      <td>811</td>\n",
       "      <td>1374.547724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13593</th>\n",
       "      <td>1500</td>\n",
       "      <td>1884.554239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>1600</td>\n",
       "      <td>1888.164112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27843</th>\n",
       "      <td>1200</td>\n",
       "      <td>1883.476675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14069</th>\n",
       "      <td>834</td>\n",
       "      <td>1374.547724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26982</th>\n",
       "      <td>882</td>\n",
       "      <td>1378.516799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>889</td>\n",
       "      <td>1453.408074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15697</th>\n",
       "      <td>1300</td>\n",
       "      <td>1374.547724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34059</th>\n",
       "      <td>839</td>\n",
       "      <td>1381.683083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31213</th>\n",
       "      <td>935</td>\n",
       "      <td>1381.244545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27962</th>\n",
       "      <td>576</td>\n",
       "      <td>1885.261409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36065</th>\n",
       "      <td>1100</td>\n",
       "      <td>1374.547724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>1000</td>\n",
       "      <td>1448.531411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35264</th>\n",
       "      <td>1100</td>\n",
       "      <td>1374.547724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual    Predicted\n",
       "6658     5000  1888.164112\n",
       "26805     811  1374.547724\n",
       "13593    1500  1884.554239\n",
       "7388     1600  1888.164112\n",
       "27843    1200  1883.476675\n",
       "14069     834  1374.547724\n",
       "26982     882  1378.516799\n",
       "11569     889  1453.408074\n",
       "15697    1300  1374.547724\n",
       "34059     839  1381.683083\n",
       "31213     935  1381.244545\n",
       "27962     576  1885.261409\n",
       "36065    1100  1374.547724\n",
       "11988    1000  1448.531411\n",
       "35264    1100  1374.547724"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a comparison of a sample of predictions and actual values\n",
    "# aside from the generally poor success rate, it is noticeable how much less variance there is\n",
    "# in the predictions, when compared with the true values. could this still be the effects of\n",
    "# the very widely-spaced distribution of the target feature? \n",
    "predictions_sample = rf_best_params.predict(X_test)[:15]\n",
    "true_vals_sample = y_test[:15]\n",
    "pd.DataFrame({'Predicted':predictions_sample, 'Actual': true_vals_sample})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>New approach: use Random Forests Classifier to check if I can have more success treating this as a classification problem</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model, using params found in randomised search (see above). if i had more time, would run a separate search,\n",
    "# in case ideal params would be different for the classifier model. \n",
    "rf_cls = RandomForestClassifier(n_estimators=200, max_depth=2, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the target feature to binary categories. initially using just the median value\n",
    "# as a threshold. 1 means popular (above the median) and 0 not popular.\n",
    "df['shares_binary'] = np.where(df['shares'] >=df['shares'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['shares_binary', 'shares'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['shares_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (training set):  0.646\n",
      "Confusion matrix (training samples): \n",
      " [[256 216]\n",
      " [138 390]]\n",
      "Classification report (training samples):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.54      0.59       472\n",
      "          1       0.64      0.74      0.69       528\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy initially seems ok, but when evaluated against the test set, significant overfitting is apparent.\n",
    "rf_cls_predictions = rf_cls.predict(X_train)[:1000]\n",
    "\n",
    "print(\"Accuracy (training set): \", accuracy_score(y_train[:1000], rf_cls_predictions))\n",
    "print(\"Confusion matrix (training samples): \\n\", confusion_matrix(y_train[:1000], rf_cls_predictions))\n",
    "print(\"Classification report (training samples):\\n \", classification_report(y_train[:1000], rf_cls_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test set):  0.496\n",
      "Confusion matrix (test set): \n",
      " [[179 282]\n",
      " [222 317]]\n",
      "Classification report (test set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.39      0.42       461\n",
      "          1       0.53      0.59      0.56       539\n",
      "\n",
      "avg / total       0.49      0.50      0.49      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (test set): \", accuracy_score(y_test[:1000], rf_cls_predictions))\n",
    "print(\"Confusion matrix (test set): \\n\", confusion_matrix(y_test[:1000], rf_cls_predictions))\n",
    "print(\"Classification report (test set):\\n \", classification_report(y_test[:1000], rf_cls_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the above figures are disappointing, so will try another randomised search grid to find best \n",
    "# params for this classifier model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using a randomised search grid to find the optimal parameters for the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'n_estimators': [10, 50, 100, 150, 200, 500, 1000], 'max_depth': [2,4,6,10,15,None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_cls_random = RandomizedSearchCV(estimator = rf_cls, param_distributions = grid, n_iter = 20, cv=3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 50, 100, 150, 200, 500, 1000], 'max_depth': [2, 4, 6, 10, 15, None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: takes 20-30 mins to run. results should be displayed below on load.\n",
    "rf_cls_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cls_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_cls_best_params = RandomForestClassifier(n_estimators=1000, max_depth=15, oob_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cls_best_params.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (training set):  0.962\n",
      "Confusion matrix (training samples): \n",
      " [[456  16]\n",
      " [ 22 506]]\n",
      "Classification report (training samples):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96       472\n",
      "          1       0.97      0.96      0.96       528\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# severe overfitting on this model iteration. not successful.\n",
    "cls_best_params_predictions = rf_cls_best_params.predict(X_train)[:1000]\n",
    "\n",
    "print(\"Accuracy (training set): \", accuracy_score(y_train[:1000], cls_best_params_predictions))\n",
    "print(\"Confusion matrix (training samples): \\n\", confusion_matrix(y_train[:1000], cls_best_params_predictions))\n",
    "print(\"Classification report (training samples):\\n \", classification_report(y_train[:1000], cls_best_params_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test set):  0.492\n",
      "Confusion matrix (test set): \n",
      " [[235 265]\n",
      " [243 257]]\n",
      "Classification report (test set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.47      0.48       500\n",
      "          1       0.49      0.51      0.50       500\n",
      "\n",
      "avg / total       0.49      0.49      0.49      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (test set): \", accuracy_score(y_test[:1000], cls_best_params_predictions))\n",
    "print(\"Confusion matrix (test set): \\n\", confusion_matrix(y_test[:1000], cls_best_params_predictions))\n",
    "print(\"Classification report (test set):\\n \", classification_report(y_test[:1000], cls_best_params_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, none of the models are satisfactory. Given more time, I would look into ways to deal with a target feature with such a skewed distribution. In experiments not documented in this Notebook, I tested models with even lower outlier cut-offs and found that the more I eliminated the widely spaced upper end of the values, the better a success rate the model seemed to have. However, this quickly got to the point where the true nature of the dataset was being eroded and the potential usefulness of the model was fading. I'm sure that with more experience in the field I would have other ideas as to how to handle this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>One final experiment...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kw_avg_avg</td>\n",
       "      <td>0.537719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data_channel_is_entertainment</td>\n",
       "      <td>0.278287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data_channel_is_tech</td>\n",
       "      <td>0.139244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>0.031236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data_channel_is_socmed</td>\n",
       "      <td>0.003954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>self_reference_avg_sharess</td>\n",
       "      <td>0.003301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>self_reference_min_shares</td>\n",
       "      <td>0.002660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LDA_04</td>\n",
       "      <td>0.002019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kw_max_max</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kw_avg_max</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_tokens_title</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LDA_02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LDA_03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>global_sentiment_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LDA_01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LDA_00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>weekday_is_sunday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>global_subjectivity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>global_rate_negative_words</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>global_rate_positive_words</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>weekday_is_friday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rate_positive_words</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rate_negative_words</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>avg_positive_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>min_positive_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>max_positive_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>avg_negative_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>min_negative_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>max_negative_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>title_subjectivity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>title_sentiment_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>abs_title_subjectivity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>weekday_is_saturday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weekday_is_monday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weekday_is_thursday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>weekday_is_wednesday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_unique_tokens</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_non_stop_words</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_non_stop_unique_tokens</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_hrefs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_self_hrefs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_imgs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_videos</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>average_token_length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_keywords</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data_channel_is_lifestyle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data_channel_is_bus</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data_channel_is_world</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kw_min_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kw_max_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kw_avg_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kw_min_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kw_min_avg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kw_max_avg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>self_reference_max_shares</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_tokens_content</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weekday_is_tuesday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>abs_title_sentiment_polarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "25                     kw_avg_avg    0.537719\n",
       "12  data_channel_is_entertainment    0.278287\n",
       "15           data_channel_is_tech    0.139244\n",
       "36                     is_weekend    0.031236\n",
       "14         data_channel_is_socmed    0.003954\n",
       "28     self_reference_avg_sharess    0.003301\n",
       "26      self_reference_min_shares    0.002660\n",
       "41                         LDA_04    0.002019\n",
       "21                     kw_max_max    0.000826\n",
       "22                     kw_avg_max    0.000754\n",
       "0                  n_tokens_title    0.000000\n",
       "39                         LDA_02    0.000000\n",
       "40                         LDA_03    0.000000\n",
       "43      global_sentiment_polarity    0.000000\n",
       "38                         LDA_01    0.000000\n",
       "37                         LDA_00    0.000000\n",
       "35              weekday_is_sunday    0.000000\n",
       "42            global_subjectivity    0.000000\n",
       "45     global_rate_negative_words    0.000000\n",
       "44     global_rate_positive_words    0.000000\n",
       "33              weekday_is_friday    0.000000\n",
       "46            rate_positive_words    0.000000\n",
       "47            rate_negative_words    0.000000\n",
       "48          avg_positive_polarity    0.000000\n",
       "49          min_positive_polarity    0.000000\n",
       "50          max_positive_polarity    0.000000\n",
       "51          avg_negative_polarity    0.000000\n",
       "52          min_negative_polarity    0.000000\n",
       "53          max_negative_polarity    0.000000\n",
       "54             title_subjectivity    0.000000\n",
       "55       title_sentiment_polarity    0.000000\n",
       "56         abs_title_subjectivity    0.000000\n",
       "34            weekday_is_saturday    0.000000\n",
       "29              weekday_is_monday    0.000000\n",
       "32            weekday_is_thursday    0.000000\n",
       "31           weekday_is_wednesday    0.000000\n",
       "2                 n_unique_tokens    0.000000\n",
       "3                n_non_stop_words    0.000000\n",
       "4        n_non_stop_unique_tokens    0.000000\n",
       "5                       num_hrefs    0.000000\n",
       "6                  num_self_hrefs    0.000000\n",
       "7                        num_imgs    0.000000\n",
       "8                      num_videos    0.000000\n",
       "9            average_token_length    0.000000\n",
       "10                   num_keywords    0.000000\n",
       "11      data_channel_is_lifestyle    0.000000\n",
       "13            data_channel_is_bus    0.000000\n",
       "16          data_channel_is_world    0.000000\n",
       "17                     kw_min_min    0.000000\n",
       "18                     kw_max_min    0.000000\n",
       "19                     kw_avg_min    0.000000\n",
       "20                     kw_min_max    0.000000\n",
       "23                     kw_min_avg    0.000000\n",
       "24                     kw_max_avg    0.000000\n",
       "27      self_reference_max_shares    0.000000\n",
       "1                n_tokens_content    0.000000\n",
       "30             weekday_is_tuesday    0.000000\n",
       "57   abs_title_sentiment_polarity    0.000000"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features ranked by importance\n",
    "# we used this table to select features for a linear regression model\n",
    "# see linear regression notebook for results...\n",
    "f_imps = pd.DataFrame({'feature': X.columns, 'importance':rf_best_params.feature_importances_})\n",
    "f_imps.sort_values(by=['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment\n",
    "1.How will the model be integrated into the organisation?\n",
    "Mashable faces a choice in how to integrate the model. Given our findings on the importance of links to other popular articles and keywords shared with other popular articles, they could either 'chase popularity' by sticking to these popular networks - or they could risk occasionally producing more innovative topics that might strike a chord with readers but might struggle algorithmically to generate shares, at least in the short term.\n",
    "\n",
    "With regard to the popular LDA topics 2 and 3, articles scoring close to these topics could be studied to get a sense of what is popular in terms of style and article content - this knowledge could then be used to influence what work editors commission in future.\n",
    "\n",
    "Furthermore, although timing of publication and word count did not feature among the most influential features, in certain cases an editor might wish to look at them to judge which day and time to post a piece to reach the maximum audience possible (all other things being equal), so some further research into this might allow enable the deployment of such knowledge.\n",
    "\n",
    "2.How will we continue to evaluate the model after deployment?\n",
    "We would recommend updating the model with new data from Mashable as time goes on as trends and public tastes may change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
